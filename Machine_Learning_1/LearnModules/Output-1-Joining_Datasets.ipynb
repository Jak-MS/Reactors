{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "# Section 1.1: A deep(er) dive into joining and cleaning datasets\n",
        "\n",
        "As a general rule, data scientists assume that about 80 percent of the time and effort devoted to a project will be spent preparing data for anlaysis. Because most real-world data is split among multiple existing datasets, this invariably means cleaning and joining diffent datasets together in the way that a data scientist needs for analysis. Thus, mastering these skills is essential for undertaking data science.\n",
        "\n",
        "This section makes extensive use of pandas, the principal Python library for data handling and manipulation. Note that this section assumes some familiarity with pandas and basic Python skills.\n",
        "\n",
        "In order to provide an experience more like real-world data science, we will use real data taken gathered from the [U.S. Department of Agriculture National Nutrient Database for Standard Reference](https://www.ars.usda.gov/northeast-area/beltsville-md-bhnrc/beltsville-human-nutrition-research-center/nutrient-data-laboratory/docs/usda-national-nutrient-database-for-standard-reference/)."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "## Reminders about importing, built-in Help, and documentation\n",
        "\n",
        "The standard convention in Python-centric data science is to import pandas under the alias `pd`, which is what we will use here:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "Because this is such a common convention, it is the way we will use and refer to pandas throughout the rest of this section and this course. You should also adopt this usage in your own code to make it easily readable for other data scientists.\n",
        "\n",
        "Pandas is a big package and there can be a lot to keep track of. Fortunately, IPython (the underlying program that powers this notebook and other like it) gives you the ability to quickly explore the contents of a package like pandas by using its tab-completion feature. If you want to see all of the functions available with pandas, type this:\n",
        "\n",
        "```ipython\n",
        "In [2]: pd.<TAB>\n",
        "\n",
        "```\n",
        "\n",
        "When you do so, a drop-down menu will appear next to the `pd`.\n",
        "\n",
        "> **Exercise**"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "# Place your cursor after the period and press <TAB>:\n",
        "pd.compat\n",
        "\n",
        "# Now select an item using tab-completion and then add a period\n",
        "# and use tab-completion to explore *that*.\n",
        "# For example, you could try placing pressing <TAB> after:\n",
        "# pd.DataFrame.\n",
        ""
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "<module 'pandas.compat' from 'C:\\\\Users\\\\v-jokoke\\\\Anaconda3\\\\lib\\\\site-packages\\\\pandas\\\\compat\\\\__init__.py'>"
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "As we progress through Section 1.1, don't forget that IPython also provides a tab-completion feature and function documentation with the `?` (question mark) character. If you don't understand something about a function you see in this section, taking a moment to csonult the documentation can help a great deal. You will find this documentation to be a very valuable reference source for your own data science work, both now and in the future. As a reminder, use this code to display the built-in pandas documentation:\n",
        "\n",
        "```ipython\n",
        "In [4]: pd?\n",
        "```\n",
        "\n",
        "> **Exercise**\n",
        "\n",
        "> Run this code cell and review the documentation for the pandas DataFrame object. We are going to use it quite a bit."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "pd "
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "<module 'pandas' from 'C:\\\\Users\\\\v-jokoke\\\\Anaconda3\\\\lib\\\\site-packages\\\\pandas\\\\__init__.py'>"
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "## A brief reminder about Jupyter notebooks\n",
        "\n",
        "This course makes extensive use of Jupyter notebooks hosted on Microsoft Azure. Azure-hosted Jupyter notebooks provide an easy way for you to experiment with programming concepts in an interactive fashion that requires no installation of software by students on local computers.\n",
        "\n",
        "Jupyter notebooks are divided into cells. Each cell either contains text written in the Markdown markup language or a space in which to write and execute computer code. Because all the code resides inside code cells, you can run each code cell inline rather than using a separate Python interactive window.\n",
        "\n",
        "> **Note**: This notebook is designed to have you run code cells one by one, and several code cells contain deliberate errors for demonstration purposes. As a result, if you use the **Cell** > **Run All** command, some code cells past the error won't be run. To resume running the code in each case, use **Cell** > **Run All Below** from the cell after the error."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "## Loading data\n",
        "\n",
        "> **Learning goal:** By the end of this subsection, you should be comfortable loading data from files into panda `DataFrame`s and troubleshooting any difficulties that might arise.\n",
        "\n",
        "Because pandas `DataFrame`s are two-dimensional data structures, they are inherently similar to flat-file formats such as comma-separated value (CSV) files, the most common import and export format for spreadsheets and databases. Adding to this ease of translation from CSV files to `DataFrame`s, pandas provides a convenient function to load the contents of CSV files into `DataFrame`s (more convenient, in fact, then the native Python [CSV library](https://docs.python.org/3.6/library/csv.html)). Let's get comfortable with [pandas.read_csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) because we will be using often."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('Data/USDA-nndb.csv')"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "After talking up the convenience of pd.read_csv, it might seem strange that we immediately encounter an error. The clue as to what went wrong is in the last line of the error message:\n",
        "\n",
        "`UnicodeDecodeError: 'utf-8' codec can't decode byte 0xf1 in position 2: invalid continuation byte`\n",
        "\n",
        "The data in the CSV file uses a character that the default Unicode Standard ([UTF-8](https://en.wikipedia.org/wiki/UTF-8)) codec reading this file doesn't understand. Remember, this is real-world data and the real world is a messy place.\n",
        "\n",
        "It's time to use the pd.read_csv documentation to look for ideas on what to try next.\n",
        "\n",
        "> **Exercise**\n",
        "\n",
        "> Use the built-in IPython documentation to on `pd.read_csv.`"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "# Hint: Refer to the discussion at the start of this section if\n",
        "# you forgot the syntax.\n",
        ""
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "There are quite a few of parameters for this function. The intuitively named `encoding` parameter accepts `str` input from the list of Python [standard encodings](https://docs.python.org/3.6/library/codecs.html#standard-encodings). We will go with `'latin_1'` here.\n",
        "\n",
        "**Note:** Although data-science practitioners do develop a familiarity with different encodings they have encountered, selecting the correct encoding can sometimes come down to trial and error, even for professionals!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('Data/USDA-nndb.csv', encoding='latin_1')"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "There was no error message this time, so `'latin_1'` did the trick and we successfully read in the CSV file to the `df` `DataFrame`."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "> **Takeaway:** There is a saying that the difference between data science in academia and the real world is that academia likes to do complex analysis on clean datasets, whereas the real world often does simpler analysis on messier datasets. Troubleshooting difficulties — even ones encountered while merely loading your data — is a large part of successful data science."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "## Exploring and cleaning the data\n",
        "\n",
        "> **Learning goal:** By the end of this subsection, you should be comfortable performing simple exploration of your data and performing simple cleaning steps on it to prepare it for later analysis.\n",
        "\n",
        "Data you'll be working with is typically in formats not necessarily designed for human consumption. Fortunately, `DataFrame` offers several tools for exploring the data. Let's explore the data we imported."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "   NDB_No               Shrt_Desc  Water_(g)  Energ_Kcal  Protein_(g)  \\\n0    1001        BUTTER,WITH SALT      15.87         717         0.85   \n1    1002  BUTTER,WHIPPED,W/ SALT      16.72         718         0.49   \n2    1003    BUTTER OIL,ANHYDROUS       0.24         876         0.28   \n3    1004             CHEESE,BLUE      42.41         353        21.40   \n4    1005            CHEESE,BRICK      41.11         371        23.24   \n\n   Lipid_Tot_(g)  Ash_(g)  Carbohydrt_(g)  Fiber_TD_(g)  Sugar_Tot_(g)  ...  \\\n0          81.11     2.11            0.06           0.0           0.06  ...   \n1          78.30     1.62            2.87           0.0           0.06  ...   \n2          99.48     0.00            0.00           0.0           0.00  ...   \n3          28.74     5.11            2.34           0.0           0.50  ...   \n4          29.68     3.18            2.79           0.0           0.51  ...   \n\n   Vit_K_(ï¿½g)  FA_Sat_(g)  FA_Mono_(g)  FA_Poly_(g)  Cholestrl_(mg)  GmWt_1  \\\n0           7.0      51.368       21.021        3.043           215.0    5.00   \n1           4.6      45.390       19.874        3.331           225.0    3.80   \n2           8.6      61.924       28.732        3.694           256.0   12.80   \n3           2.4      18.669        7.778        0.800            75.0   28.35   \n4           2.5      18.764        8.598        0.784            94.0  132.00   \n\n                   GmWt_Desc1  GmWt_2       GmWt_Desc2  Refuse_Pct  \n0  1 pat,  (1\" sq, 1/3\" high)    14.2           1 tbsp         0.0  \n1  1 pat,  (1\" sq, 1/3\" high)     9.4           1 tbsp         0.0  \n2                      1 tbsp   205.0            1 cup         0.0  \n3                        1 oz    17.0     1 cubic inch         0.0  \n4                1 cup, diced   113.0  1 cup, shredded         0.0  \n\n[5 rows x 53 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>NDB_No</th>\n      <th>Shrt_Desc</th>\n      <th>Water_(g)</th>\n      <th>Energ_Kcal</th>\n      <th>Protein_(g)</th>\n      <th>Lipid_Tot_(g)</th>\n      <th>Ash_(g)</th>\n      <th>Carbohydrt_(g)</th>\n      <th>Fiber_TD_(g)</th>\n      <th>Sugar_Tot_(g)</th>\n      <th>...</th>\n      <th>Vit_K_(ï¿½g)</th>\n      <th>FA_Sat_(g)</th>\n      <th>FA_Mono_(g)</th>\n      <th>FA_Poly_(g)</th>\n      <th>Cholestrl_(mg)</th>\n      <th>GmWt_1</th>\n      <th>GmWt_Desc1</th>\n      <th>GmWt_2</th>\n      <th>GmWt_Desc2</th>\n      <th>Refuse_Pct</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1001</td>\n      <td>BUTTER,WITH SALT</td>\n      <td>15.87</td>\n      <td>717</td>\n      <td>0.85</td>\n      <td>81.11</td>\n      <td>2.11</td>\n      <td>0.06</td>\n      <td>0.0</td>\n      <td>0.06</td>\n      <td>...</td>\n      <td>7.0</td>\n      <td>51.368</td>\n      <td>21.021</td>\n      <td>3.043</td>\n      <td>215.0</td>\n      <td>5.00</td>\n      <td>1 pat,  (1\" sq, 1/3\" high)</td>\n      <td>14.2</td>\n      <td>1 tbsp</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1002</td>\n      <td>BUTTER,WHIPPED,W/ SALT</td>\n      <td>16.72</td>\n      <td>718</td>\n      <td>0.49</td>\n      <td>78.30</td>\n      <td>1.62</td>\n      <td>2.87</td>\n      <td>0.0</td>\n      <td>0.06</td>\n      <td>...</td>\n      <td>4.6</td>\n      <td>45.390</td>\n      <td>19.874</td>\n      <td>3.331</td>\n      <td>225.0</td>\n      <td>3.80</td>\n      <td>1 pat,  (1\" sq, 1/3\" high)</td>\n      <td>9.4</td>\n      <td>1 tbsp</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1003</td>\n      <td>BUTTER OIL,ANHYDROUS</td>\n      <td>0.24</td>\n      <td>876</td>\n      <td>0.28</td>\n      <td>99.48</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>8.6</td>\n      <td>61.924</td>\n      <td>28.732</td>\n      <td>3.694</td>\n      <td>256.0</td>\n      <td>12.80</td>\n      <td>1 tbsp</td>\n      <td>205.0</td>\n      <td>1 cup</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1004</td>\n      <td>CHEESE,BLUE</td>\n      <td>42.41</td>\n      <td>353</td>\n      <td>21.40</td>\n      <td>28.74</td>\n      <td>5.11</td>\n      <td>2.34</td>\n      <td>0.0</td>\n      <td>0.50</td>\n      <td>...</td>\n      <td>2.4</td>\n      <td>18.669</td>\n      <td>7.778</td>\n      <td>0.800</td>\n      <td>75.0</td>\n      <td>28.35</td>\n      <td>1 oz</td>\n      <td>17.0</td>\n      <td>1 cubic inch</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1005</td>\n      <td>CHEESE,BRICK</td>\n      <td>41.11</td>\n      <td>371</td>\n      <td>23.24</td>\n      <td>29.68</td>\n      <td>3.18</td>\n      <td>2.79</td>\n      <td>0.0</td>\n      <td>0.51</td>\n      <td>...</td>\n      <td>2.5</td>\n      <td>18.764</td>\n      <td>8.598</td>\n      <td>0.784</td>\n      <td>94.0</td>\n      <td>132.00</td>\n      <td>1 cup, diced</td>\n      <td>113.0</td>\n      <td>1 cup, shredded</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 53 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "We can get some aggregated information about the `DataFrame` by using its `info()` method:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 8790 entries, 0 to 8789\nData columns (total 53 columns):\n #   Column              Non-Null Count  Dtype  \n---  ------              --------------  -----  \n 0   NDB_No              8790 non-null   int64  \n 1   Shrt_Desc           8790 non-null   object \n 2   Water_(g)           8789 non-null   float64\n 3   Energ_Kcal          8790 non-null   int64  \n 4   Protein_(g)         8790 non-null   float64\n 5   Lipid_Tot_(g)       8790 non-null   float64\n 6   Ash_(g)             8465 non-null   float64\n 7   Carbohydrt_(g)      8790 non-null   float64\n 8   Fiber_TD_(g)        8196 non-null   float64\n 9   Sugar_Tot_(g)       6958 non-null   float64\n 10  Calcium_(mg)        8442 non-null   float64\n 11  Iron_(mg)           8646 non-null   float64\n 12  Magnesium_(mg)      8051 non-null   float64\n 13  Phosphorus_(mg)     8211 non-null   float64\n 14  Potassium_(mg)      8364 non-null   float64\n 15  Sodium_(mg)         8707 non-null   float64\n 16  Zinc_(mg)           8084 non-null   float64\n 17  Copper_mg)          7533 non-null   float64\n 18  Manganese_(mg)      6630 non-null   float64\n 19  Selenium_(ï¿½g)     7090 non-null   float64\n 20  Vit_C_(mg)          7972 non-null   float64\n 21  Thiamin_(mg)        8156 non-null   float64\n 22  Riboflavin_(mg)     8174 non-null   float64\n 23  Niacin_(mg)         8153 non-null   float64\n 24  Panto_Acid_mg)      6548 non-null   float64\n 25  Vit_B6_(mg)         7885 non-null   float64\n 26  Folate_Tot_(ï¿½g)   7529 non-null   float64\n 27  Folic_Acid_(ï¿½g)   6751 non-null   float64\n 28  Food_Folate_(ï¿½g)  7022 non-null   float64\n 29  Folate_DFE_(ï¿½g)   6733 non-null   float64\n 30  Choline_Tot_ (mg)   4774 non-null   float64\n 31  Vit_B12_(ï¿½g)      7597 non-null   float64\n 32  Vit_A_IU            8079 non-null   float64\n 33  Vit_A_RAE           7255 non-null   float64\n 34  Retinol_(ï¿½g)      6984 non-null   float64\n 35  Alpha_Carot_(ï¿½g)  5532 non-null   float64\n 36  Beta_Carot_(ï¿½g)   5628 non-null   float64\n 37  Beta_Crypt_(ï¿½g)   5520 non-null   float64\n 38  Lycopene_(ï¿½g)     5498 non-null   float64\n 39  Lut+Zea_ (ï¿½g)     5475 non-null   float64\n 40  Vit_E_(mg)          5901 non-null   float64\n 41  Vit_D_ï¿½g          5528 non-null   float64\n 42  Vit_D_IU            5579 non-null   float64\n 43  Vit_K_(ï¿½g)        5227 non-null   float64\n 44  FA_Sat_(g)          8441 non-null   float64\n 45  FA_Mono_(g)         8124 non-null   float64\n 46  FA_Poly_(g)         8125 non-null   float64\n 47  Cholestrl_(mg)      8380 non-null   float64\n 48  GmWt_1              8490 non-null   float64\n 49  GmWt_Desc1          8491 non-null   object \n 50  GmWt_2              4825 non-null   float64\n 51  GmWt_Desc2          4825 non-null   object \n 52  Refuse_Pct          8740 non-null   float64\ndtypes: float64(48), int64(2), object(3)\nmemory usage: 3.6+ MB\n"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "Just quickly inspecting the columns from `df` we can see that almost all of the columns have a number of null values. Those missing values are not an issue for us right now, but they will pose a challenge in future sections (but we will deal with them in those sections).\n",
        "\n",
        "Let's also check to see if this `DataFrame` has any duplicate values in it. Let's start by exploring the `duplicated` method."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "df.duplicated?"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": "\u001b[1;31mSignature:\u001b[0m\n\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n\u001b[0m    \u001b[0msubset\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mHashable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSequence\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mHashable\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n\u001b[0m    \u001b[0mkeep\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'first'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m'Series'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;31mDocstring:\u001b[0m\nReturn boolean Series denoting duplicate rows.\n\nConsidering certain columns is optional.\n\nParameters\n----------\nsubset : column label or sequence of labels, optional\n    Only consider certain columns for identifying duplicates, by\n    default use all of the columns.\nkeep : {'first', 'last', False}, default 'first'\n    Determines which duplicates (if any) to mark.\n\n    - ``first`` : Mark duplicates as ``True`` except for the first occurrence.\n    - ``last`` : Mark duplicates as ``True`` except for the last occurrence.\n    - False : Mark all duplicates as ``True``.\n\nReturns\n-------\nSeries\n\u001b[1;31mFile:\u001b[0m      c:\\users\\v-jokoke\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\n\u001b[1;31mType:\u001b[0m      method\n",
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "df.duplicated()"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "0       False\n1       False\n2       False\n3       False\n4       False\n        ...  \n8785    False\n8786    False\n8787    False\n8788    False\n8789    False\nLength: 8790, dtype: bool"
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "You'll notice the results from `duplicated` shows the result on a row by row basis. Not exactly the most efficient way of determining if there's duplicated rows. One quick trick we can use is to call `sum`, which will add the values of the results, where `False` will be **0** and `True` will be **1**. The end result will be we will get a rough sense if there's any duplicated rows."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "df.duplicated().sum()"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "0"
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "Given the nature of the data source (a government reference database) it makes sense that there are no duplicate entries. For purposes of learning more about cleaning data, let's make a mess so we can see how we can clean it up! Let's start by duplicating data by using the `append()` method."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "df = df.append(df, ignore_index=True)"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "The `append()` method has basically stacked the `DataFrame` by appending a copy of `df` to the end of the `DataFrame`. (In SQL terms, we performed a [UNION](https://www.w3schools.com/sql/sql_union.asp)). The `ignore_index=True` parameter means that the internal index numbering for the newly doubled `DataFrame` continues seamlessly.\n",
        "\n",
        "Now let's look directly at how many times individual values in a column (such as `NDB_No`, which is a key) are duplicated. We'll use the `groupby` function to create a \"group\" for each instance of `NDB_No`, and then we'll count each instance."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "df.groupby('NDB_No')['NDB_No'].count()"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "NDB_No\n1001     2\n1002     2\n1003     2\n1004     2\n1005     2\n        ..\n83110    2\n90240    2\n90480    2\n90560    2\n93600    2\nName: NDB_No, Length: 8790, dtype: int64"
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "Given that we duplicated the original dataset, two duplicates of everything is not unexpected. However, these duplicate values will pose a problem for us later in the section if not dealt with, so let's take care of them now:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "df = df.drop_duplicates('NDB_No', keep=\"last\")\n",
        "df.info()"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 8790 entries, 8790 to 17579\nData columns (total 53 columns):\n #   Column              Non-Null Count  Dtype  \n---  ------              --------------  -----  \n 0   NDB_No              8790 non-null   int64  \n 1   Shrt_Desc           8790 non-null   object \n 2   Water_(g)           8789 non-null   float64\n 3   Energ_Kcal          8790 non-null   int64  \n 4   Protein_(g)         8790 non-null   float64\n 5   Lipid_Tot_(g)       8790 non-null   float64\n 6   Ash_(g)             8465 non-null   float64\n 7   Carbohydrt_(g)      8790 non-null   float64\n 8   Fiber_TD_(g)        8196 non-null   float64\n 9   Sugar_Tot_(g)       6958 non-null   float64\n 10  Calcium_(mg)        8442 non-null   float64\n 11  Iron_(mg)           8646 non-null   float64\n 12  Magnesium_(mg)      8051 non-null   float64\n 13  Phosphorus_(mg)     8211 non-null   float64\n 14  Potassium_(mg)      8364 non-null   float64\n 15  Sodium_(mg)         8707 non-null   float64\n 16  Zinc_(mg)           8084 non-null   float64\n 17  Copper_mg)          7533 non-null   float64\n 18  Manganese_(mg)      6630 non-null   float64\n 19  Selenium_(ï¿½g)     7090 non-null   float64\n 20  Vit_C_(mg)          7972 non-null   float64\n 21  Thiamin_(mg)        8156 non-null   float64\n 22  Riboflavin_(mg)     8174 non-null   float64\n 23  Niacin_(mg)         8153 non-null   float64\n 24  Panto_Acid_mg)      6548 non-null   float64\n 25  Vit_B6_(mg)         7885 non-null   float64\n 26  Folate_Tot_(ï¿½g)   7529 non-null   float64\n 27  Folic_Acid_(ï¿½g)   6751 non-null   float64\n 28  Food_Folate_(ï¿½g)  7022 non-null   float64\n 29  Folate_DFE_(ï¿½g)   6733 non-null   float64\n 30  Choline_Tot_ (mg)   4774 non-null   float64\n 31  Vit_B12_(ï¿½g)      7597 non-null   float64\n 32  Vit_A_IU            8079 non-null   float64\n 33  Vit_A_RAE           7255 non-null   float64\n 34  Retinol_(ï¿½g)      6984 non-null   float64\n 35  Alpha_Carot_(ï¿½g)  5532 non-null   float64\n 36  Beta_Carot_(ï¿½g)   5628 non-null   float64\n 37  Beta_Crypt_(ï¿½g)   5520 non-null   float64\n 38  Lycopene_(ï¿½g)     5498 non-null   float64\n 39  Lut+Zea_ (ï¿½g)     5475 non-null   float64\n 40  Vit_E_(mg)          5901 non-null   float64\n 41  Vit_D_ï¿½g          5528 non-null   float64\n 42  Vit_D_IU            5579 non-null   float64\n 43  Vit_K_(ï¿½g)        5227 non-null   float64\n 44  FA_Sat_(g)          8441 non-null   float64\n 45  FA_Mono_(g)         8124 non-null   float64\n 46  FA_Poly_(g)         8125 non-null   float64\n 47  Cholestrl_(mg)      8380 non-null   float64\n 48  GmWt_1              8490 non-null   float64\n 49  GmWt_Desc1          8491 non-null   object \n 50  GmWt_2              4825 non-null   float64\n 51  GmWt_Desc2          4825 non-null   object \n 52  Refuse_Pct          8740 non-null   float64\ndtypes: float64(48), int64(2), object(3)\nmemory usage: 3.6+ MB\n"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "The `DataFrame` is now half of its previous size, which is what we would expect. However, look at this line in the `df.info()` output:\n",
        "\n",
        "`Int64Index: 8790 entries, 8790 to 17579`\n",
        "\n",
        "Remember, counting starts with zero. But while there are only now 8790 entries per column, the indexing for the DataFrame does not run 0 through 8789, as we might have expected. We can see this more directly by looking at the `head` of the redacted `DataFrame`:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "      NDB_No               Shrt_Desc  Water_(g)  Energ_Kcal  Protein_(g)  \\\n8790    1001        BUTTER,WITH SALT      15.87         717         0.85   \n8791    1002  BUTTER,WHIPPED,W/ SALT      16.72         718         0.49   \n8792    1003    BUTTER OIL,ANHYDROUS       0.24         876         0.28   \n8793    1004             CHEESE,BLUE      42.41         353        21.40   \n8794    1005            CHEESE,BRICK      41.11         371        23.24   \n\n      Lipid_Tot_(g)  Ash_(g)  Carbohydrt_(g)  Fiber_TD_(g)  Sugar_Tot_(g)  \\\n8790          81.11     2.11            0.06           0.0           0.06   \n8791          78.30     1.62            2.87           0.0           0.06   \n8792          99.48     0.00            0.00           0.0           0.00   \n8793          28.74     5.11            2.34           0.0           0.50   \n8794          29.68     3.18            2.79           0.0           0.51   \n\n      ...  Vit_K_(ï¿½g)  FA_Sat_(g)  FA_Mono_(g)  FA_Poly_(g)  Cholestrl_(mg)  \\\n8790  ...           7.0      51.368       21.021        3.043           215.0   \n8791  ...           4.6      45.390       19.874        3.331           225.0   \n8792  ...           8.6      61.924       28.732        3.694           256.0   \n8793  ...           2.4      18.669        7.778        0.800            75.0   \n8794  ...           2.5      18.764        8.598        0.784            94.0   \n\n      GmWt_1                  GmWt_Desc1  GmWt_2       GmWt_Desc2  Refuse_Pct  \n8790    5.00  1 pat,  (1\" sq, 1/3\" high)    14.2           1 tbsp         0.0  \n8791    3.80  1 pat,  (1\" sq, 1/3\" high)     9.4           1 tbsp         0.0  \n8792   12.80                      1 tbsp   205.0            1 cup         0.0  \n8793   28.35                        1 oz    17.0     1 cubic inch         0.0  \n8794  132.00                1 cup, diced   113.0  1 cup, shredded         0.0  \n\n[5 rows x 53 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>NDB_No</th>\n      <th>Shrt_Desc</th>\n      <th>Water_(g)</th>\n      <th>Energ_Kcal</th>\n      <th>Protein_(g)</th>\n      <th>Lipid_Tot_(g)</th>\n      <th>Ash_(g)</th>\n      <th>Carbohydrt_(g)</th>\n      <th>Fiber_TD_(g)</th>\n      <th>Sugar_Tot_(g)</th>\n      <th>...</th>\n      <th>Vit_K_(ï¿½g)</th>\n      <th>FA_Sat_(g)</th>\n      <th>FA_Mono_(g)</th>\n      <th>FA_Poly_(g)</th>\n      <th>Cholestrl_(mg)</th>\n      <th>GmWt_1</th>\n      <th>GmWt_Desc1</th>\n      <th>GmWt_2</th>\n      <th>GmWt_Desc2</th>\n      <th>Refuse_Pct</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8790</th>\n      <td>1001</td>\n      <td>BUTTER,WITH SALT</td>\n      <td>15.87</td>\n      <td>717</td>\n      <td>0.85</td>\n      <td>81.11</td>\n      <td>2.11</td>\n      <td>0.06</td>\n      <td>0.0</td>\n      <td>0.06</td>\n      <td>...</td>\n      <td>7.0</td>\n      <td>51.368</td>\n      <td>21.021</td>\n      <td>3.043</td>\n      <td>215.0</td>\n      <td>5.00</td>\n      <td>1 pat,  (1\" sq, 1/3\" high)</td>\n      <td>14.2</td>\n      <td>1 tbsp</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8791</th>\n      <td>1002</td>\n      <td>BUTTER,WHIPPED,W/ SALT</td>\n      <td>16.72</td>\n      <td>718</td>\n      <td>0.49</td>\n      <td>78.30</td>\n      <td>1.62</td>\n      <td>2.87</td>\n      <td>0.0</td>\n      <td>0.06</td>\n      <td>...</td>\n      <td>4.6</td>\n      <td>45.390</td>\n      <td>19.874</td>\n      <td>3.331</td>\n      <td>225.0</td>\n      <td>3.80</td>\n      <td>1 pat,  (1\" sq, 1/3\" high)</td>\n      <td>9.4</td>\n      <td>1 tbsp</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8792</th>\n      <td>1003</td>\n      <td>BUTTER OIL,ANHYDROUS</td>\n      <td>0.24</td>\n      <td>876</td>\n      <td>0.28</td>\n      <td>99.48</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>8.6</td>\n      <td>61.924</td>\n      <td>28.732</td>\n      <td>3.694</td>\n      <td>256.0</td>\n      <td>12.80</td>\n      <td>1 tbsp</td>\n      <td>205.0</td>\n      <td>1 cup</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8793</th>\n      <td>1004</td>\n      <td>CHEESE,BLUE</td>\n      <td>42.41</td>\n      <td>353</td>\n      <td>21.40</td>\n      <td>28.74</td>\n      <td>5.11</td>\n      <td>2.34</td>\n      <td>0.0</td>\n      <td>0.50</td>\n      <td>...</td>\n      <td>2.4</td>\n      <td>18.669</td>\n      <td>7.778</td>\n      <td>0.800</td>\n      <td>75.0</td>\n      <td>28.35</td>\n      <td>1 oz</td>\n      <td>17.0</td>\n      <td>1 cubic inch</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8794</th>\n      <td>1005</td>\n      <td>CHEESE,BRICK</td>\n      <td>41.11</td>\n      <td>371</td>\n      <td>23.24</td>\n      <td>29.68</td>\n      <td>3.18</td>\n      <td>2.79</td>\n      <td>0.0</td>\n      <td>0.51</td>\n      <td>...</td>\n      <td>2.5</td>\n      <td>18.764</td>\n      <td>8.598</td>\n      <td>0.784</td>\n      <td>94.0</td>\n      <td>132.00</td>\n      <td>1 cup, diced</td>\n      <td>113.0</td>\n      <td>1 cup, shredded</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 53 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "> **Question**\n",
        ">\n",
        "> Is this behavior of the `drop_duplicates()` method not updating the index values of the `DataFrame` surprising or unexpected for you? Can you explain why this method behaves as it does in this case? If not, study the documentation for this method by using `df.drop_duplicates?` in the code cell below until you're satisfied with your understanding of this behavior."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "> **Takeaway:** Duplicate, `Null`, and `NaN` values can all complicate (if not derail) your analysis. Learning how to identify and remove these problems is a huge part of successfully performing data science."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "## Splitting the `DataFrame`\n",
        "\n",
        "> **Learning goal:** By the end of this subsection, you should be comfortable selecting and dropping specific columns from a `DataFrame`.\n",
        "\n",
        "It might seem strange to discuss splitting a `DataFrame` in a course section on joining them, but we'll do so here to create the `DataFrame`s that we'll join later on. We take this approach for two reasons:\n",
        "\n",
        "1. Creating our own `DataFrame`s gives us easy control over the content of the child `DataFrame`s to best demonstrate aspects of joining datasets.\n",
        "2. Because we have a baseline, joined `DataFrame` (`df`), it's easy to see how different methods of joining the child `DataFrame`s produce different results.\n",
        "\n",
        "We're going to create two child `DataFrame`s, `df1` and `df2`. `df1` will contain the first 35 columns of our data, while `df2` will contain the rest. This will allow us to explore how we can manipulate and manage columns in a dataset, and to simulate a common scenario where some of the data you need is in one location, while the rest is in a different location."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "df1 = df.iloc[:,:35]"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "> **Exercise**\n",
        "\n",
        "> Why did we use syntax `df1 = df.iloc[:,:35]` to capture the first 35 columns of `df`? What does the first `:` (colon) in the square brackets do? Experiment with `df3 = df.iloc[:35]` in the code cell below and compare `df3.info()` with `df1.info()` to satisfy yourself as to why we need to use this syntax."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "df1.info()"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 8790 entries, 8790 to 17579\nData columns (total 35 columns):\n #   Column              Non-Null Count  Dtype  \n---  ------              --------------  -----  \n 0   NDB_No              8790 non-null   int64  \n 1   Shrt_Desc           8790 non-null   object \n 2   Water_(g)           8789 non-null   float64\n 3   Energ_Kcal          8790 non-null   int64  \n 4   Protein_(g)         8790 non-null   float64\n 5   Lipid_Tot_(g)       8790 non-null   float64\n 6   Ash_(g)             8465 non-null   float64\n 7   Carbohydrt_(g)      8790 non-null   float64\n 8   Fiber_TD_(g)        8196 non-null   float64\n 9   Sugar_Tot_(g)       6958 non-null   float64\n 10  Calcium_(mg)        8442 non-null   float64\n 11  Iron_(mg)           8646 non-null   float64\n 12  Magnesium_(mg)      8051 non-null   float64\n 13  Phosphorus_(mg)     8211 non-null   float64\n 14  Potassium_(mg)      8364 non-null   float64\n 15  Sodium_(mg)         8707 non-null   float64\n 16  Zinc_(mg)           8084 non-null   float64\n 17  Copper_mg)          7533 non-null   float64\n 18  Manganese_(mg)      6630 non-null   float64\n 19  Selenium_(ï¿½g)     7090 non-null   float64\n 20  Vit_C_(mg)          7972 non-null   float64\n 21  Thiamin_(mg)        8156 non-null   float64\n 22  Riboflavin_(mg)     8174 non-null   float64\n 23  Niacin_(mg)         8153 non-null   float64\n 24  Panto_Acid_mg)      6548 non-null   float64\n 25  Vit_B6_(mg)         7885 non-null   float64\n 26  Folate_Tot_(ï¿½g)   7529 non-null   float64\n 27  Folic_Acid_(ï¿½g)   6751 non-null   float64\n 28  Food_Folate_(ï¿½g)  7022 non-null   float64\n 29  Folate_DFE_(ï¿½g)   6733 non-null   float64\n 30  Choline_Tot_ (mg)   4774 non-null   float64\n 31  Vit_B12_(ï¿½g)      7597 non-null   float64\n 32  Vit_A_IU            8079 non-null   float64\n 33  Vit_A_RAE           7255 non-null   float64\n 34  Retinol_(ï¿½g)      6984 non-null   float64\ndtypes: float64(32), int64(2), object(1)\nmemory usage: 2.4+ MB\n"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "## Let's create df2\n",
        "\n",
        "We'll create `df2` in a similar manner to `df1`, but we need to do things a little differently here to ensure that the first columne (`NDB_No`) makes it into `df2`. This is going to serve as the column that's common to both child `DataFrame`s when we join them later in this section.\n",
        "\n",
        "We also want to populate `df2` with a different number of rows than `df1`, again simulating real world scenarios. Doing so will make is easier to demonstrate what goes on with some of the join techniques shown below."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "df2 = df.iloc[0:2000, [0]+[i for i in range(35,53)]]"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "> **Question**\n",
        "\n",
        "> If you're unsure about why we use `[0] + [i for i in range(35,53)]` in the list comprehension above, review the documentation for the `range()` function using `range?` in the code cell below. You may want to run `[0] + [i for i in range(35,53)]` in the cell below as part of your exploration, and play around with adding (or concatenating) arrays. And remember Python uses zero-based indexing."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "We can examine `df2` by using the `head()` and `info()` methods."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "df2.head()"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "      NDB_No  Alpha_Carot_(ï¿½g)  Beta_Carot_(ï¿½g)  Beta_Crypt_(ï¿½g)  \\\n8790    1001                 0.0              158.0                0.0   \n8791    1002                 1.0              135.0                6.0   \n8792    1003                 0.0              193.0                0.0   \n8793    1004                 0.0               74.0                0.0   \n8794    1005                 0.0               76.0                0.0   \n\n      Lycopene_(ï¿½g)  Lut+Zea_ (ï¿½g)  Vit_E_(mg)  Vit_D_ï¿½g  Vit_D_IU  \\\n8790              0.0              0.0        2.32         0.0       0.0   \n8791              0.0             13.0        1.37         0.0       0.0   \n8792              0.0              0.0        2.80         0.0       0.0   \n8793              0.0              0.0        0.25         0.5      21.0   \n8794              0.0              0.0        0.26         0.5      22.0   \n\n      Vit_K_(ï¿½g)  FA_Sat_(g)  FA_Mono_(g)  FA_Poly_(g)  Cholestrl_(mg)  \\\n8790           7.0      51.368       21.021        3.043           215.0   \n8791           4.6      45.390       19.874        3.331           225.0   \n8792           8.6      61.924       28.732        3.694           256.0   \n8793           2.4      18.669        7.778        0.800            75.0   \n8794           2.5      18.764        8.598        0.784            94.0   \n\n      GmWt_1                  GmWt_Desc1  GmWt_2       GmWt_Desc2  Refuse_Pct  \n8790    5.00  1 pat,  (1\" sq, 1/3\" high)    14.2           1 tbsp         0.0  \n8791    3.80  1 pat,  (1\" sq, 1/3\" high)     9.4           1 tbsp         0.0  \n8792   12.80                      1 tbsp   205.0            1 cup         0.0  \n8793   28.35                        1 oz    17.0     1 cubic inch         0.0  \n8794  132.00                1 cup, diced   113.0  1 cup, shredded         0.0  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>NDB_No</th>\n      <th>Alpha_Carot_(ï¿½g)</th>\n      <th>Beta_Carot_(ï¿½g)</th>\n      <th>Beta_Crypt_(ï¿½g)</th>\n      <th>Lycopene_(ï¿½g)</th>\n      <th>Lut+Zea_ (ï¿½g)</th>\n      <th>Vit_E_(mg)</th>\n      <th>Vit_D_ï¿½g</th>\n      <th>Vit_D_IU</th>\n      <th>Vit_K_(ï¿½g)</th>\n      <th>FA_Sat_(g)</th>\n      <th>FA_Mono_(g)</th>\n      <th>FA_Poly_(g)</th>\n      <th>Cholestrl_(mg)</th>\n      <th>GmWt_1</th>\n      <th>GmWt_Desc1</th>\n      <th>GmWt_2</th>\n      <th>GmWt_Desc2</th>\n      <th>Refuse_Pct</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8790</th>\n      <td>1001</td>\n      <td>0.0</td>\n      <td>158.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.32</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>7.0</td>\n      <td>51.368</td>\n      <td>21.021</td>\n      <td>3.043</td>\n      <td>215.0</td>\n      <td>5.00</td>\n      <td>1 pat,  (1\" sq, 1/3\" high)</td>\n      <td>14.2</td>\n      <td>1 tbsp</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8791</th>\n      <td>1002</td>\n      <td>1.0</td>\n      <td>135.0</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>13.0</td>\n      <td>1.37</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.6</td>\n      <td>45.390</td>\n      <td>19.874</td>\n      <td>3.331</td>\n      <td>225.0</td>\n      <td>3.80</td>\n      <td>1 pat,  (1\" sq, 1/3\" high)</td>\n      <td>9.4</td>\n      <td>1 tbsp</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8792</th>\n      <td>1003</td>\n      <td>0.0</td>\n      <td>193.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.80</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>8.6</td>\n      <td>61.924</td>\n      <td>28.732</td>\n      <td>3.694</td>\n      <td>256.0</td>\n      <td>12.80</td>\n      <td>1 tbsp</td>\n      <td>205.0</td>\n      <td>1 cup</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8793</th>\n      <td>1004</td>\n      <td>0.0</td>\n      <td>74.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.25</td>\n      <td>0.5</td>\n      <td>21.0</td>\n      <td>2.4</td>\n      <td>18.669</td>\n      <td>7.778</td>\n      <td>0.800</td>\n      <td>75.0</td>\n      <td>28.35</td>\n      <td>1 oz</td>\n      <td>17.0</td>\n      <td>1 cubic inch</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8794</th>\n      <td>1005</td>\n      <td>0.0</td>\n      <td>76.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.26</td>\n      <td>0.5</td>\n      <td>22.0</td>\n      <td>2.5</td>\n      <td>18.764</td>\n      <td>8.598</td>\n      <td>0.784</td>\n      <td>94.0</td>\n      <td>132.00</td>\n      <td>1 cup, diced</td>\n      <td>113.0</td>\n      <td>1 cup, shredded</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "df2.info()"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 2000 entries, 8790 to 10789\nData columns (total 19 columns):\n #   Column              Non-Null Count  Dtype  \n---  ------              --------------  -----  \n 0   NDB_No              2000 non-null   int64  \n 1   Alpha_Carot_(ï¿½g)  1426 non-null   float64\n 2   Beta_Carot_(ï¿½g)   1447 non-null   float64\n 3   Beta_Crypt_(ï¿½g)   1425 non-null   float64\n 4   Lycopene_(ï¿½g)     1426 non-null   float64\n 5   Lut+Zea_ (ï¿½g)     1418 non-null   float64\n 6   Vit_E_(mg)          1456 non-null   float64\n 7   Vit_D_ï¿½g          1289 non-null   float64\n 8   Vit_D_IU            1289 non-null   float64\n 9   Vit_K_(ï¿½g)        1359 non-null   float64\n 10  FA_Sat_(g)          1965 non-null   float64\n 11  FA_Mono_(g)         1823 non-null   float64\n 12  FA_Poly_(g)         1825 non-null   float64\n 13  Cholestrl_(mg)      1947 non-null   float64\n 14  GmWt_1              1967 non-null   float64\n 15  GmWt_Desc1          1967 non-null   object \n 16  GmWt_2              1171 non-null   float64\n 17  GmWt_Desc2          1171 non-null   object \n 18  Refuse_Pct          2000 non-null   float64\ndtypes: float64(16), int64(1), object(2)\nmemory usage: 312.5+ KB\n"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "Let’s take a look at `df1`."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "df1.head()"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "      NDB_No               Shrt_Desc  Water_(g)  Energ_Kcal  Protein_(g)  \\\n8790    1001        BUTTER,WITH SALT      15.87         717         0.85   \n8791    1002  BUTTER,WHIPPED,W/ SALT      16.72         718         0.49   \n8792    1003    BUTTER OIL,ANHYDROUS       0.24         876         0.28   \n8793    1004             CHEESE,BLUE      42.41         353        21.40   \n8794    1005            CHEESE,BRICK      41.11         371        23.24   \n\n      Lipid_Tot_(g)  Ash_(g)  Carbohydrt_(g)  Fiber_TD_(g)  Sugar_Tot_(g)  \\\n8790          81.11     2.11            0.06           0.0           0.06   \n8791          78.30     1.62            2.87           0.0           0.06   \n8792          99.48     0.00            0.00           0.0           0.00   \n8793          28.74     5.11            2.34           0.0           0.50   \n8794          29.68     3.18            2.79           0.0           0.51   \n\n      ...  Vit_B6_(mg)  Folate_Tot_(ï¿½g)  Folic_Acid_(ï¿½g)  \\\n8790  ...        0.003                3.0                0.0   \n8791  ...        0.008                4.0                0.0   \n8792  ...        0.001                0.0                0.0   \n8793  ...        0.166               36.0                0.0   \n8794  ...        0.065               20.0                0.0   \n\n      Food_Folate_(ï¿½g)  Folate_DFE_(ï¿½g)  Choline_Tot_ (mg)  \\\n8790                 3.0                3.0               18.8   \n8791                 4.0                4.0               18.8   \n8792                 0.0                0.0               22.3   \n8793                36.0               36.0               15.4   \n8794                20.0               20.0               15.4   \n\n      Vit_B12_(ï¿½g)  Vit_A_IU  Vit_A_RAE  Retinol_(ï¿½g)  \n8790            0.17    2499.0      684.0           671.0  \n8791            0.07    2468.0      683.0           671.0  \n8792            0.01    3069.0      840.0           824.0  \n8793            1.22     721.0      198.0           192.0  \n8794            1.26    1080.0      292.0           286.0  \n\n[5 rows x 35 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>NDB_No</th>\n      <th>Shrt_Desc</th>\n      <th>Water_(g)</th>\n      <th>Energ_Kcal</th>\n      <th>Protein_(g)</th>\n      <th>Lipid_Tot_(g)</th>\n      <th>Ash_(g)</th>\n      <th>Carbohydrt_(g)</th>\n      <th>Fiber_TD_(g)</th>\n      <th>Sugar_Tot_(g)</th>\n      <th>...</th>\n      <th>Vit_B6_(mg)</th>\n      <th>Folate_Tot_(ï¿½g)</th>\n      <th>Folic_Acid_(ï¿½g)</th>\n      <th>Food_Folate_(ï¿½g)</th>\n      <th>Folate_DFE_(ï¿½g)</th>\n      <th>Choline_Tot_ (mg)</th>\n      <th>Vit_B12_(ï¿½g)</th>\n      <th>Vit_A_IU</th>\n      <th>Vit_A_RAE</th>\n      <th>Retinol_(ï¿½g)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8790</th>\n      <td>1001</td>\n      <td>BUTTER,WITH SALT</td>\n      <td>15.87</td>\n      <td>717</td>\n      <td>0.85</td>\n      <td>81.11</td>\n      <td>2.11</td>\n      <td>0.06</td>\n      <td>0.0</td>\n      <td>0.06</td>\n      <td>...</td>\n      <td>0.003</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>18.8</td>\n      <td>0.17</td>\n      <td>2499.0</td>\n      <td>684.0</td>\n      <td>671.0</td>\n    </tr>\n    <tr>\n      <th>8791</th>\n      <td>1002</td>\n      <td>BUTTER,WHIPPED,W/ SALT</td>\n      <td>16.72</td>\n      <td>718</td>\n      <td>0.49</td>\n      <td>78.30</td>\n      <td>1.62</td>\n      <td>2.87</td>\n      <td>0.0</td>\n      <td>0.06</td>\n      <td>...</td>\n      <td>0.008</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>18.8</td>\n      <td>0.07</td>\n      <td>2468.0</td>\n      <td>683.0</td>\n      <td>671.0</td>\n    </tr>\n    <tr>\n      <th>8792</th>\n      <td>1003</td>\n      <td>BUTTER OIL,ANHYDROUS</td>\n      <td>0.24</td>\n      <td>876</td>\n      <td>0.28</td>\n      <td>99.48</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.001</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>22.3</td>\n      <td>0.01</td>\n      <td>3069.0</td>\n      <td>840.0</td>\n      <td>824.0</td>\n    </tr>\n    <tr>\n      <th>8793</th>\n      <td>1004</td>\n      <td>CHEESE,BLUE</td>\n      <td>42.41</td>\n      <td>353</td>\n      <td>21.40</td>\n      <td>28.74</td>\n      <td>5.11</td>\n      <td>2.34</td>\n      <td>0.0</td>\n      <td>0.50</td>\n      <td>...</td>\n      <td>0.166</td>\n      <td>36.0</td>\n      <td>0.0</td>\n      <td>36.0</td>\n      <td>36.0</td>\n      <td>15.4</td>\n      <td>1.22</td>\n      <td>721.0</td>\n      <td>198.0</td>\n      <td>192.0</td>\n    </tr>\n    <tr>\n      <th>8794</th>\n      <td>1005</td>\n      <td>CHEESE,BRICK</td>\n      <td>41.11</td>\n      <td>371</td>\n      <td>23.24</td>\n      <td>29.68</td>\n      <td>3.18</td>\n      <td>2.79</td>\n      <td>0.0</td>\n      <td>0.51</td>\n      <td>...</td>\n      <td>0.065</td>\n      <td>20.0</td>\n      <td>0.0</td>\n      <td>20.0</td>\n      <td>20.0</td>\n      <td>15.4</td>\n      <td>1.26</td>\n      <td>1080.0</td>\n      <td>292.0</td>\n      <td>286.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 35 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "You'll notice on that both `DataFrame`s have their old indices indexes that they inherited from  `df`. We can fix that by using the `reset_index()` method, but then we run into a problem."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "df1 = df1.reset_index()\n",
        "df1.head()"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "   index  NDB_No               Shrt_Desc  Water_(g)  Energ_Kcal  Protein_(g)  \\\n0   8790    1001        BUTTER,WITH SALT      15.87         717         0.85   \n1   8791    1002  BUTTER,WHIPPED,W/ SALT      16.72         718         0.49   \n2   8792    1003    BUTTER OIL,ANHYDROUS       0.24         876         0.28   \n3   8793    1004             CHEESE,BLUE      42.41         353        21.40   \n4   8794    1005            CHEESE,BRICK      41.11         371        23.24   \n\n   Lipid_Tot_(g)  Ash_(g)  Carbohydrt_(g)  Fiber_TD_(g)  ...  Vit_B6_(mg)  \\\n0          81.11     2.11            0.06           0.0  ...        0.003   \n1          78.30     1.62            2.87           0.0  ...        0.008   \n2          99.48     0.00            0.00           0.0  ...        0.001   \n3          28.74     5.11            2.34           0.0  ...        0.166   \n4          29.68     3.18            2.79           0.0  ...        0.065   \n\n   Folate_Tot_(ï¿½g)  Folic_Acid_(ï¿½g)  Food_Folate_(ï¿½g)  \\\n0                3.0                0.0                 3.0   \n1                4.0                0.0                 4.0   \n2                0.0                0.0                 0.0   \n3               36.0                0.0                36.0   \n4               20.0                0.0                20.0   \n\n   Folate_DFE_(ï¿½g)  Choline_Tot_ (mg)  Vit_B12_(ï¿½g)  Vit_A_IU  Vit_A_RAE  \\\n0                3.0               18.8            0.17    2499.0      684.0   \n1                4.0               18.8            0.07    2468.0      683.0   \n2                0.0               22.3            0.01    3069.0      840.0   \n3               36.0               15.4            1.22     721.0      198.0   \n4               20.0               15.4            1.26    1080.0      292.0   \n\n   Retinol_(ï¿½g)  \n0           671.0  \n1           671.0  \n2           824.0  \n3           192.0  \n4           286.0  \n\n[5 rows x 36 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>NDB_No</th>\n      <th>Shrt_Desc</th>\n      <th>Water_(g)</th>\n      <th>Energ_Kcal</th>\n      <th>Protein_(g)</th>\n      <th>Lipid_Tot_(g)</th>\n      <th>Ash_(g)</th>\n      <th>Carbohydrt_(g)</th>\n      <th>Fiber_TD_(g)</th>\n      <th>...</th>\n      <th>Vit_B6_(mg)</th>\n      <th>Folate_Tot_(ï¿½g)</th>\n      <th>Folic_Acid_(ï¿½g)</th>\n      <th>Food_Folate_(ï¿½g)</th>\n      <th>Folate_DFE_(ï¿½g)</th>\n      <th>Choline_Tot_ (mg)</th>\n      <th>Vit_B12_(ï¿½g)</th>\n      <th>Vit_A_IU</th>\n      <th>Vit_A_RAE</th>\n      <th>Retinol_(ï¿½g)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8790</td>\n      <td>1001</td>\n      <td>BUTTER,WITH SALT</td>\n      <td>15.87</td>\n      <td>717</td>\n      <td>0.85</td>\n      <td>81.11</td>\n      <td>2.11</td>\n      <td>0.06</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.003</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>18.8</td>\n      <td>0.17</td>\n      <td>2499.0</td>\n      <td>684.0</td>\n      <td>671.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8791</td>\n      <td>1002</td>\n      <td>BUTTER,WHIPPED,W/ SALT</td>\n      <td>16.72</td>\n      <td>718</td>\n      <td>0.49</td>\n      <td>78.30</td>\n      <td>1.62</td>\n      <td>2.87</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.008</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>18.8</td>\n      <td>0.07</td>\n      <td>2468.0</td>\n      <td>683.0</td>\n      <td>671.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8792</td>\n      <td>1003</td>\n      <td>BUTTER OIL,ANHYDROUS</td>\n      <td>0.24</td>\n      <td>876</td>\n      <td>0.28</td>\n      <td>99.48</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.001</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>22.3</td>\n      <td>0.01</td>\n      <td>3069.0</td>\n      <td>840.0</td>\n      <td>824.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8793</td>\n      <td>1004</td>\n      <td>CHEESE,BLUE</td>\n      <td>42.41</td>\n      <td>353</td>\n      <td>21.40</td>\n      <td>28.74</td>\n      <td>5.11</td>\n      <td>2.34</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.166</td>\n      <td>36.0</td>\n      <td>0.0</td>\n      <td>36.0</td>\n      <td>36.0</td>\n      <td>15.4</td>\n      <td>1.22</td>\n      <td>721.0</td>\n      <td>198.0</td>\n      <td>192.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8794</td>\n      <td>1005</td>\n      <td>CHEESE,BRICK</td>\n      <td>41.11</td>\n      <td>371</td>\n      <td>23.24</td>\n      <td>29.68</td>\n      <td>3.18</td>\n      <td>2.79</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.065</td>\n      <td>20.0</td>\n      <td>0.0</td>\n      <td>20.0</td>\n      <td>20.0</td>\n      <td>15.4</td>\n      <td>1.26</td>\n      <td>1080.0</td>\n      <td>292.0</td>\n      <td>286.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 36 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "Our old indexes are still there for `df1`, but now they're in a new column titled `index`. pandas doesn't want to delete data we might need. We can instruct pandas to remove the column, which we know is unnecessary, by using the `drop=True` parameter for the method. (We also need to drop the `index` column we just created in the prior step.)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "df1 = df1.drop(['index'], axis=1) #remove the index we created previously\n",
        "df1 = df1.reset_index(drop=True) #reset the index and tell pandas not to create the copy\n",
        "df1.head()"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "   NDB_No               Shrt_Desc  Water_(g)  Energ_Kcal  Protein_(g)  \\\n0    1001        BUTTER,WITH SALT      15.87         717         0.85   \n1    1002  BUTTER,WHIPPED,W/ SALT      16.72         718         0.49   \n2    1003    BUTTER OIL,ANHYDROUS       0.24         876         0.28   \n3    1004             CHEESE,BLUE      42.41         353        21.40   \n4    1005            CHEESE,BRICK      41.11         371        23.24   \n\n   Lipid_Tot_(g)  Ash_(g)  Carbohydrt_(g)  Fiber_TD_(g)  Sugar_Tot_(g)  ...  \\\n0          81.11     2.11            0.06           0.0           0.06  ...   \n1          78.30     1.62            2.87           0.0           0.06  ...   \n2          99.48     0.00            0.00           0.0           0.00  ...   \n3          28.74     5.11            2.34           0.0           0.50  ...   \n4          29.68     3.18            2.79           0.0           0.51  ...   \n\n   Vit_B6_(mg)  Folate_Tot_(ï¿½g)  Folic_Acid_(ï¿½g)  Food_Folate_(ï¿½g)  \\\n0        0.003                3.0                0.0                 3.0   \n1        0.008                4.0                0.0                 4.0   \n2        0.001                0.0                0.0                 0.0   \n3        0.166               36.0                0.0                36.0   \n4        0.065               20.0                0.0                20.0   \n\n   Folate_DFE_(ï¿½g)  Choline_Tot_ (mg)  Vit_B12_(ï¿½g)  Vit_A_IU  Vit_A_RAE  \\\n0                3.0               18.8            0.17    2499.0      684.0   \n1                4.0               18.8            0.07    2468.0      683.0   \n2                0.0               22.3            0.01    3069.0      840.0   \n3               36.0               15.4            1.22     721.0      198.0   \n4               20.0               15.4            1.26    1080.0      292.0   \n\n   Retinol_(ï¿½g)  \n0           671.0  \n1           671.0  \n2           824.0  \n3           192.0  \n4           286.0  \n\n[5 rows x 35 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>NDB_No</th>\n      <th>Shrt_Desc</th>\n      <th>Water_(g)</th>\n      <th>Energ_Kcal</th>\n      <th>Protein_(g)</th>\n      <th>Lipid_Tot_(g)</th>\n      <th>Ash_(g)</th>\n      <th>Carbohydrt_(g)</th>\n      <th>Fiber_TD_(g)</th>\n      <th>Sugar_Tot_(g)</th>\n      <th>...</th>\n      <th>Vit_B6_(mg)</th>\n      <th>Folate_Tot_(ï¿½g)</th>\n      <th>Folic_Acid_(ï¿½g)</th>\n      <th>Food_Folate_(ï¿½g)</th>\n      <th>Folate_DFE_(ï¿½g)</th>\n      <th>Choline_Tot_ (mg)</th>\n      <th>Vit_B12_(ï¿½g)</th>\n      <th>Vit_A_IU</th>\n      <th>Vit_A_RAE</th>\n      <th>Retinol_(ï¿½g)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1001</td>\n      <td>BUTTER,WITH SALT</td>\n      <td>15.87</td>\n      <td>717</td>\n      <td>0.85</td>\n      <td>81.11</td>\n      <td>2.11</td>\n      <td>0.06</td>\n      <td>0.0</td>\n      <td>0.06</td>\n      <td>...</td>\n      <td>0.003</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>18.8</td>\n      <td>0.17</td>\n      <td>2499.0</td>\n      <td>684.0</td>\n      <td>671.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1002</td>\n      <td>BUTTER,WHIPPED,W/ SALT</td>\n      <td>16.72</td>\n      <td>718</td>\n      <td>0.49</td>\n      <td>78.30</td>\n      <td>1.62</td>\n      <td>2.87</td>\n      <td>0.0</td>\n      <td>0.06</td>\n      <td>...</td>\n      <td>0.008</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>18.8</td>\n      <td>0.07</td>\n      <td>2468.0</td>\n      <td>683.0</td>\n      <td>671.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1003</td>\n      <td>BUTTER OIL,ANHYDROUS</td>\n      <td>0.24</td>\n      <td>876</td>\n      <td>0.28</td>\n      <td>99.48</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.001</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>22.3</td>\n      <td>0.01</td>\n      <td>3069.0</td>\n      <td>840.0</td>\n      <td>824.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1004</td>\n      <td>CHEESE,BLUE</td>\n      <td>42.41</td>\n      <td>353</td>\n      <td>21.40</td>\n      <td>28.74</td>\n      <td>5.11</td>\n      <td>2.34</td>\n      <td>0.0</td>\n      <td>0.50</td>\n      <td>...</td>\n      <td>0.166</td>\n      <td>36.0</td>\n      <td>0.0</td>\n      <td>36.0</td>\n      <td>36.0</td>\n      <td>15.4</td>\n      <td>1.22</td>\n      <td>721.0</td>\n      <td>198.0</td>\n      <td>192.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1005</td>\n      <td>CHEESE,BRICK</td>\n      <td>41.11</td>\n      <td>371</td>\n      <td>23.24</td>\n      <td>29.68</td>\n      <td>3.18</td>\n      <td>2.79</td>\n      <td>0.0</td>\n      <td>0.51</td>\n      <td>...</td>\n      <td>0.065</td>\n      <td>20.0</td>\n      <td>0.0</td>\n      <td>20.0</td>\n      <td>20.0</td>\n      <td>15.4</td>\n      <td>1.26</td>\n      <td>1080.0</td>\n      <td>292.0</td>\n      <td>286.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 35 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "Now let's do the same thing to `df2`."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "df2 = df2.reset_index(drop=True)\n",
        "df2.head()"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "   NDB_No  Alpha_Carot_(ï¿½g)  Beta_Carot_(ï¿½g)  Beta_Crypt_(ï¿½g)  \\\n0    1001                 0.0              158.0                0.0   \n1    1002                 1.0              135.0                6.0   \n2    1003                 0.0              193.0                0.0   \n3    1004                 0.0               74.0                0.0   \n4    1005                 0.0               76.0                0.0   \n\n   Lycopene_(ï¿½g)  Lut+Zea_ (ï¿½g)  Vit_E_(mg)  Vit_D_ï¿½g  Vit_D_IU  \\\n0              0.0              0.0        2.32         0.0       0.0   \n1              0.0             13.0        1.37         0.0       0.0   \n2              0.0              0.0        2.80         0.0       0.0   \n3              0.0              0.0        0.25         0.5      21.0   \n4              0.0              0.0        0.26         0.5      22.0   \n\n   Vit_K_(ï¿½g)  FA_Sat_(g)  FA_Mono_(g)  FA_Poly_(g)  Cholestrl_(mg)  GmWt_1  \\\n0           7.0      51.368       21.021        3.043           215.0    5.00   \n1           4.6      45.390       19.874        3.331           225.0    3.80   \n2           8.6      61.924       28.732        3.694           256.0   12.80   \n3           2.4      18.669        7.778        0.800            75.0   28.35   \n4           2.5      18.764        8.598        0.784            94.0  132.00   \n\n                   GmWt_Desc1  GmWt_2       GmWt_Desc2  Refuse_Pct  \n0  1 pat,  (1\" sq, 1/3\" high)    14.2           1 tbsp         0.0  \n1  1 pat,  (1\" sq, 1/3\" high)     9.4           1 tbsp         0.0  \n2                      1 tbsp   205.0            1 cup         0.0  \n3                        1 oz    17.0     1 cubic inch         0.0  \n4                1 cup, diced   113.0  1 cup, shredded         0.0  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>NDB_No</th>\n      <th>Alpha_Carot_(ï¿½g)</th>\n      <th>Beta_Carot_(ï¿½g)</th>\n      <th>Beta_Crypt_(ï¿½g)</th>\n      <th>Lycopene_(ï¿½g)</th>\n      <th>Lut+Zea_ (ï¿½g)</th>\n      <th>Vit_E_(mg)</th>\n      <th>Vit_D_ï¿½g</th>\n      <th>Vit_D_IU</th>\n      <th>Vit_K_(ï¿½g)</th>\n      <th>FA_Sat_(g)</th>\n      <th>FA_Mono_(g)</th>\n      <th>FA_Poly_(g)</th>\n      <th>Cholestrl_(mg)</th>\n      <th>GmWt_1</th>\n      <th>GmWt_Desc1</th>\n      <th>GmWt_2</th>\n      <th>GmWt_Desc2</th>\n      <th>Refuse_Pct</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1001</td>\n      <td>0.0</td>\n      <td>158.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.32</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>7.0</td>\n      <td>51.368</td>\n      <td>21.021</td>\n      <td>3.043</td>\n      <td>215.0</td>\n      <td>5.00</td>\n      <td>1 pat,  (1\" sq, 1/3\" high)</td>\n      <td>14.2</td>\n      <td>1 tbsp</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1002</td>\n      <td>1.0</td>\n      <td>135.0</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>13.0</td>\n      <td>1.37</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.6</td>\n      <td>45.390</td>\n      <td>19.874</td>\n      <td>3.331</td>\n      <td>225.0</td>\n      <td>3.80</td>\n      <td>1 pat,  (1\" sq, 1/3\" high)</td>\n      <td>9.4</td>\n      <td>1 tbsp</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1003</td>\n      <td>0.0</td>\n      <td>193.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.80</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>8.6</td>\n      <td>61.924</td>\n      <td>28.732</td>\n      <td>3.694</td>\n      <td>256.0</td>\n      <td>12.80</td>\n      <td>1 tbsp</td>\n      <td>205.0</td>\n      <td>1 cup</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1004</td>\n      <td>0.0</td>\n      <td>74.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.25</td>\n      <td>0.5</td>\n      <td>21.0</td>\n      <td>2.4</td>\n      <td>18.669</td>\n      <td>7.778</td>\n      <td>0.800</td>\n      <td>75.0</td>\n      <td>28.35</td>\n      <td>1 oz</td>\n      <td>17.0</td>\n      <td>1 cubic inch</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1005</td>\n      <td>0.0</td>\n      <td>76.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.26</td>\n      <td>0.5</td>\n      <td>22.0</td>\n      <td>2.5</td>\n      <td>18.764</td>\n      <td>8.598</td>\n      <td>0.784</td>\n      <td>94.0</td>\n      <td>132.00</td>\n      <td>1 cup, diced</td>\n      <td>113.0</td>\n      <td>1 cup, shredded</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "For practice, let's export these `DataFrame`s to CSV files by using the `to_csv()` method. Note that unless we explicitly tell pandas not to, it will also export the index as a column in the CSV file. We will also need to be careful to explicitly encode our CSV to UTF-8."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "df1.to_csv('Data/NNDB1.csv', sep=',', encoding='utf-8',index=False)"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "> **Exercise**"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "# Export df2 to a CSV file.\n",
        ""
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "> **Takeaway:** Although it's not common in the real world to split `DataFrame`s only to re-merge them later, you'll need to drop columns or create new `DataFrame`s that contain only the information you need. With truly large datasets, this is not just a convenience for you analysis, but a necessity for memory and performance!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "## Joining `DataFrame`s\n",
        "\n",
        "> **Learning goal:** By the end of this subsection, you should be comfortable performing left, right, inner, and outer merges on `DataFrame`s.\n",
        "\n",
        "We'll examine the  most commonly used `DataFrame` function for joining datasets: `merge()`. But first, let's refresh ourselves on the shapes of our two `DataFrame`s so that the output of our joining makes more sense. This will display the number of rows and columns in each `DataFrame`."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "df1.shape"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "(8790, 35)"
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "df2.shape"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "(2000, 19)"
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "The type of dataset join that’s most widely used by practicing data scientists is the left join. If you already have some experience with SQL, you know what this refers to. Basically, a left join is a join that takes all of the data from one `DataFrame` (think of it as the left set in a Venn diagram) and merges it with everything that it has in common with another `DataFrame` (the intersection with the right set in the same Venn diagram).\n",
        "\n",
        "We do this using the `merge()` function. We also need to specify the type of join we want to perform by using the `how` parameter, as well as the index on which to join the `DataFrames` by using the `on` parameter."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "# Similar to the SQL:\n",
        "# FROM df1 LEFT JOIN df2 ON df1.NBD_No = df2.NBD_No\n",
        "\n",
        "left_df = pd.merge(df1, df2, how='left', on='NDB_No')\n",
        "left_df.shape"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "(8790, 53)"
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "> **Question**\n",
        "\n",
        "> Is the shape of the resulting `DataFrame` what you were expecting? Why or why not?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "Now let's compare this to the original `df` `DataFrame`."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "(8790, 53)"
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "> **Question**\n",
        "\n",
        "> The shapes are the same, but do you expect `df` and `left_df` to be identical? If so, why? If not, what differences do you expect there to be between them?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "Let's check to see what the differences between these `DataFrame`s might be."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "      NDB_No               Shrt_Desc  Water_(g)  Energ_Kcal  Protein_(g)  \\\n8790    1001        BUTTER,WITH SALT      15.87         717         0.85   \n8791    1002  BUTTER,WHIPPED,W/ SALT      16.72         718         0.49   \n8792    1003    BUTTER OIL,ANHYDROUS       0.24         876         0.28   \n8793    1004             CHEESE,BLUE      42.41         353        21.40   \n8794    1005            CHEESE,BRICK      41.11         371        23.24   \n\n      Lipid_Tot_(g)  Ash_(g)  Carbohydrt_(g)  Fiber_TD_(g)  Sugar_Tot_(g)  \\\n8790          81.11     2.11            0.06           0.0           0.06   \n8791          78.30     1.62            2.87           0.0           0.06   \n8792          99.48     0.00            0.00           0.0           0.00   \n8793          28.74     5.11            2.34           0.0           0.50   \n8794          29.68     3.18            2.79           0.0           0.51   \n\n      ...  Vit_K_(ï¿½g)  FA_Sat_(g)  FA_Mono_(g)  FA_Poly_(g)  Cholestrl_(mg)  \\\n8790  ...           7.0      51.368       21.021        3.043           215.0   \n8791  ...           4.6      45.390       19.874        3.331           225.0   \n8792  ...           8.6      61.924       28.732        3.694           256.0   \n8793  ...           2.4      18.669        7.778        0.800            75.0   \n8794  ...           2.5      18.764        8.598        0.784            94.0   \n\n      GmWt_1                  GmWt_Desc1  GmWt_2       GmWt_Desc2  Refuse_Pct  \n8790    5.00  1 pat,  (1\" sq, 1/3\" high)    14.2           1 tbsp         0.0  \n8791    3.80  1 pat,  (1\" sq, 1/3\" high)     9.4           1 tbsp         0.0  \n8792   12.80                      1 tbsp   205.0            1 cup         0.0  \n8793   28.35                        1 oz    17.0     1 cubic inch         0.0  \n8794  132.00                1 cup, diced   113.0  1 cup, shredded         0.0  \n\n[5 rows x 53 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>NDB_No</th>\n      <th>Shrt_Desc</th>\n      <th>Water_(g)</th>\n      <th>Energ_Kcal</th>\n      <th>Protein_(g)</th>\n      <th>Lipid_Tot_(g)</th>\n      <th>Ash_(g)</th>\n      <th>Carbohydrt_(g)</th>\n      <th>Fiber_TD_(g)</th>\n      <th>Sugar_Tot_(g)</th>\n      <th>...</th>\n      <th>Vit_K_(ï¿½g)</th>\n      <th>FA_Sat_(g)</th>\n      <th>FA_Mono_(g)</th>\n      <th>FA_Poly_(g)</th>\n      <th>Cholestrl_(mg)</th>\n      <th>GmWt_1</th>\n      <th>GmWt_Desc1</th>\n      <th>GmWt_2</th>\n      <th>GmWt_Desc2</th>\n      <th>Refuse_Pct</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8790</th>\n      <td>1001</td>\n      <td>BUTTER,WITH SALT</td>\n      <td>15.87</td>\n      <td>717</td>\n      <td>0.85</td>\n      <td>81.11</td>\n      <td>2.11</td>\n      <td>0.06</td>\n      <td>0.0</td>\n      <td>0.06</td>\n      <td>...</td>\n      <td>7.0</td>\n      <td>51.368</td>\n      <td>21.021</td>\n      <td>3.043</td>\n      <td>215.0</td>\n      <td>5.00</td>\n      <td>1 pat,  (1\" sq, 1/3\" high)</td>\n      <td>14.2</td>\n      <td>1 tbsp</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8791</th>\n      <td>1002</td>\n      <td>BUTTER,WHIPPED,W/ SALT</td>\n      <td>16.72</td>\n      <td>718</td>\n      <td>0.49</td>\n      <td>78.30</td>\n      <td>1.62</td>\n      <td>2.87</td>\n      <td>0.0</td>\n      <td>0.06</td>\n      <td>...</td>\n      <td>4.6</td>\n      <td>45.390</td>\n      <td>19.874</td>\n      <td>3.331</td>\n      <td>225.0</td>\n      <td>3.80</td>\n      <td>1 pat,  (1\" sq, 1/3\" high)</td>\n      <td>9.4</td>\n      <td>1 tbsp</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8792</th>\n      <td>1003</td>\n      <td>BUTTER OIL,ANHYDROUS</td>\n      <td>0.24</td>\n      <td>876</td>\n      <td>0.28</td>\n      <td>99.48</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>8.6</td>\n      <td>61.924</td>\n      <td>28.732</td>\n      <td>3.694</td>\n      <td>256.0</td>\n      <td>12.80</td>\n      <td>1 tbsp</td>\n      <td>205.0</td>\n      <td>1 cup</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8793</th>\n      <td>1004</td>\n      <td>CHEESE,BLUE</td>\n      <td>42.41</td>\n      <td>353</td>\n      <td>21.40</td>\n      <td>28.74</td>\n      <td>5.11</td>\n      <td>2.34</td>\n      <td>0.0</td>\n      <td>0.50</td>\n      <td>...</td>\n      <td>2.4</td>\n      <td>18.669</td>\n      <td>7.778</td>\n      <td>0.800</td>\n      <td>75.0</td>\n      <td>28.35</td>\n      <td>1 oz</td>\n      <td>17.0</td>\n      <td>1 cubic inch</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8794</th>\n      <td>1005</td>\n      <td>CHEESE,BRICK</td>\n      <td>41.11</td>\n      <td>371</td>\n      <td>23.24</td>\n      <td>29.68</td>\n      <td>3.18</td>\n      <td>2.79</td>\n      <td>0.0</td>\n      <td>0.51</td>\n      <td>...</td>\n      <td>2.5</td>\n      <td>18.764</td>\n      <td>8.598</td>\n      <td>0.784</td>\n      <td>94.0</td>\n      <td>132.00</td>\n      <td>1 cup, diced</td>\n      <td>113.0</td>\n      <td>1 cup, shredded</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 53 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "left_df.head()"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "   NDB_No               Shrt_Desc  Water_(g)  Energ_Kcal  Protein_(g)  \\\n0    1001        BUTTER,WITH SALT      15.87         717         0.85   \n1    1002  BUTTER,WHIPPED,W/ SALT      16.72         718         0.49   \n2    1003    BUTTER OIL,ANHYDROUS       0.24         876         0.28   \n3    1004             CHEESE,BLUE      42.41         353        21.40   \n4    1005            CHEESE,BRICK      41.11         371        23.24   \n\n   Lipid_Tot_(g)  Ash_(g)  Carbohydrt_(g)  Fiber_TD_(g)  Sugar_Tot_(g)  ...  \\\n0          81.11     2.11            0.06           0.0           0.06  ...   \n1          78.30     1.62            2.87           0.0           0.06  ...   \n2          99.48     0.00            0.00           0.0           0.00  ...   \n3          28.74     5.11            2.34           0.0           0.50  ...   \n4          29.68     3.18            2.79           0.0           0.51  ...   \n\n   Vit_K_(ï¿½g)  FA_Sat_(g)  FA_Mono_(g)  FA_Poly_(g)  Cholestrl_(mg)  GmWt_1  \\\n0           7.0      51.368       21.021        3.043           215.0    5.00   \n1           4.6      45.390       19.874        3.331           225.0    3.80   \n2           8.6      61.924       28.732        3.694           256.0   12.80   \n3           2.4      18.669        7.778        0.800            75.0   28.35   \n4           2.5      18.764        8.598        0.784            94.0  132.00   \n\n                   GmWt_Desc1  GmWt_2       GmWt_Desc2  Refuse_Pct  \n0  1 pat,  (1\" sq, 1/3\" high)    14.2           1 tbsp         0.0  \n1  1 pat,  (1\" sq, 1/3\" high)     9.4           1 tbsp         0.0  \n2                      1 tbsp   205.0            1 cup         0.0  \n3                        1 oz    17.0     1 cubic inch         0.0  \n4                1 cup, diced   113.0  1 cup, shredded         0.0  \n\n[5 rows x 53 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>NDB_No</th>\n      <th>Shrt_Desc</th>\n      <th>Water_(g)</th>\n      <th>Energ_Kcal</th>\n      <th>Protein_(g)</th>\n      <th>Lipid_Tot_(g)</th>\n      <th>Ash_(g)</th>\n      <th>Carbohydrt_(g)</th>\n      <th>Fiber_TD_(g)</th>\n      <th>Sugar_Tot_(g)</th>\n      <th>...</th>\n      <th>Vit_K_(ï¿½g)</th>\n      <th>FA_Sat_(g)</th>\n      <th>FA_Mono_(g)</th>\n      <th>FA_Poly_(g)</th>\n      <th>Cholestrl_(mg)</th>\n      <th>GmWt_1</th>\n      <th>GmWt_Desc1</th>\n      <th>GmWt_2</th>\n      <th>GmWt_Desc2</th>\n      <th>Refuse_Pct</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1001</td>\n      <td>BUTTER,WITH SALT</td>\n      <td>15.87</td>\n      <td>717</td>\n      <td>0.85</td>\n      <td>81.11</td>\n      <td>2.11</td>\n      <td>0.06</td>\n      <td>0.0</td>\n      <td>0.06</td>\n      <td>...</td>\n      <td>7.0</td>\n      <td>51.368</td>\n      <td>21.021</td>\n      <td>3.043</td>\n      <td>215.0</td>\n      <td>5.00</td>\n      <td>1 pat,  (1\" sq, 1/3\" high)</td>\n      <td>14.2</td>\n      <td>1 tbsp</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1002</td>\n      <td>BUTTER,WHIPPED,W/ SALT</td>\n      <td>16.72</td>\n      <td>718</td>\n      <td>0.49</td>\n      <td>78.30</td>\n      <td>1.62</td>\n      <td>2.87</td>\n      <td>0.0</td>\n      <td>0.06</td>\n      <td>...</td>\n      <td>4.6</td>\n      <td>45.390</td>\n      <td>19.874</td>\n      <td>3.331</td>\n      <td>225.0</td>\n      <td>3.80</td>\n      <td>1 pat,  (1\" sq, 1/3\" high)</td>\n      <td>9.4</td>\n      <td>1 tbsp</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1003</td>\n      <td>BUTTER OIL,ANHYDROUS</td>\n      <td>0.24</td>\n      <td>876</td>\n      <td>0.28</td>\n      <td>99.48</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>8.6</td>\n      <td>61.924</td>\n      <td>28.732</td>\n      <td>3.694</td>\n      <td>256.0</td>\n      <td>12.80</td>\n      <td>1 tbsp</td>\n      <td>205.0</td>\n      <td>1 cup</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1004</td>\n      <td>CHEESE,BLUE</td>\n      <td>42.41</td>\n      <td>353</td>\n      <td>21.40</td>\n      <td>28.74</td>\n      <td>5.11</td>\n      <td>2.34</td>\n      <td>0.0</td>\n      <td>0.50</td>\n      <td>...</td>\n      <td>2.4</td>\n      <td>18.669</td>\n      <td>7.778</td>\n      <td>0.800</td>\n      <td>75.0</td>\n      <td>28.35</td>\n      <td>1 oz</td>\n      <td>17.0</td>\n      <td>1 cubic inch</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1005</td>\n      <td>CHEESE,BRICK</td>\n      <td>41.11</td>\n      <td>371</td>\n      <td>23.24</td>\n      <td>29.68</td>\n      <td>3.18</td>\n      <td>2.79</td>\n      <td>0.0</td>\n      <td>0.51</td>\n      <td>...</td>\n      <td>2.5</td>\n      <td>18.764</td>\n      <td>8.598</td>\n      <td>0.784</td>\n      <td>94.0</td>\n      <td>132.00</td>\n      <td>1 cup, diced</td>\n      <td>113.0</td>\n      <td>1 cup, shredded</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 53 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "The indexes notwithstanding, the first five rows of both `DataFrame`s are the same. Let's check the last five rows."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "       NDB_No                   Shrt_Desc  Water_(g)  Energ_Kcal  Protein_(g)  \\\n17575   83110             MACKEREL,SALTED      43.00         305        18.50   \n17576   90240  SCALLOP,(BAY&SEA),CKD,STMD      70.25         111        20.54   \n17577   90480                  SYRUP,CANE      26.00         269         0.00   \n17578   90560                   SNAIL,RAW      79.20          90        16.10   \n17579   93600            TURTLE,GREEN,RAW      78.50          89        19.80   \n\n       Lipid_Tot_(g)  Ash_(g)  Carbohydrt_(g)  Fiber_TD_(g)  Sugar_Tot_(g)  \\\n17575          25.10    13.40            0.00           0.0            0.0   \n17576           0.84     2.97            5.41           0.0            0.0   \n17577           0.00     0.86           73.14           0.0           73.2   \n17578           1.40     1.30            2.00           0.0            0.0   \n17579           0.50     1.20            0.00           0.0            0.0   \n\n       ...  Vit_K_(ï¿½g)  FA_Sat_(g)  FA_Mono_(g)  FA_Poly_(g)  \\\n17575  ...           7.8       7.148        8.320        6.210   \n17576  ...           0.0       0.218        0.082        0.222   \n17577  ...           0.0       0.000        0.000        0.000   \n17578  ...           0.1       0.361        0.259        0.252   \n17579  ...           0.1       0.127        0.088        0.170   \n\n       Cholestrl_(mg)  GmWt_1                          GmWt_Desc1  GmWt_2  \\\n17575            95.0    80.0  1 piece,  (5-1/2\" x 1-1/2\" x 1/2\")    17.0   \n17576            41.0    85.0                                3 oz     NaN   \n17577             0.0    21.0                           1 serving     NaN   \n17578            50.0    85.0                                3 oz     NaN   \n17579            50.0    85.0                                3 oz     NaN   \n\n                   GmWt_Desc2  Refuse_Pct  \n17575  1 cubic inch, boneless         0.0  \n17576                     NaN         0.0  \n17577                     NaN         0.0  \n17578                     NaN         0.0  \n17579                     NaN         0.0  \n\n[5 rows x 53 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>NDB_No</th>\n      <th>Shrt_Desc</th>\n      <th>Water_(g)</th>\n      <th>Energ_Kcal</th>\n      <th>Protein_(g)</th>\n      <th>Lipid_Tot_(g)</th>\n      <th>Ash_(g)</th>\n      <th>Carbohydrt_(g)</th>\n      <th>Fiber_TD_(g)</th>\n      <th>Sugar_Tot_(g)</th>\n      <th>...</th>\n      <th>Vit_K_(ï¿½g)</th>\n      <th>FA_Sat_(g)</th>\n      <th>FA_Mono_(g)</th>\n      <th>FA_Poly_(g)</th>\n      <th>Cholestrl_(mg)</th>\n      <th>GmWt_1</th>\n      <th>GmWt_Desc1</th>\n      <th>GmWt_2</th>\n      <th>GmWt_Desc2</th>\n      <th>Refuse_Pct</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>17575</th>\n      <td>83110</td>\n      <td>MACKEREL,SALTED</td>\n      <td>43.00</td>\n      <td>305</td>\n      <td>18.50</td>\n      <td>25.10</td>\n      <td>13.40</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>7.8</td>\n      <td>7.148</td>\n      <td>8.320</td>\n      <td>6.210</td>\n      <td>95.0</td>\n      <td>80.0</td>\n      <td>1 piece,  (5-1/2\" x 1-1/2\" x 1/2\")</td>\n      <td>17.0</td>\n      <td>1 cubic inch, boneless</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>17576</th>\n      <td>90240</td>\n      <td>SCALLOP,(BAY&amp;SEA),CKD,STMD</td>\n      <td>70.25</td>\n      <td>111</td>\n      <td>20.54</td>\n      <td>0.84</td>\n      <td>2.97</td>\n      <td>5.41</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.218</td>\n      <td>0.082</td>\n      <td>0.222</td>\n      <td>41.0</td>\n      <td>85.0</td>\n      <td>3 oz</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>17577</th>\n      <td>90480</td>\n      <td>SYRUP,CANE</td>\n      <td>26.00</td>\n      <td>269</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.86</td>\n      <td>73.14</td>\n      <td>0.0</td>\n      <td>73.2</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>21.0</td>\n      <td>1 serving</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>17578</th>\n      <td>90560</td>\n      <td>SNAIL,RAW</td>\n      <td>79.20</td>\n      <td>90</td>\n      <td>16.10</td>\n      <td>1.40</td>\n      <td>1.30</td>\n      <td>2.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>0.361</td>\n      <td>0.259</td>\n      <td>0.252</td>\n      <td>50.0</td>\n      <td>85.0</td>\n      <td>3 oz</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>17579</th>\n      <td>93600</td>\n      <td>TURTLE,GREEN,RAW</td>\n      <td>78.50</td>\n      <td>89</td>\n      <td>19.80</td>\n      <td>0.50</td>\n      <td>1.20</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>0.127</td>\n      <td>0.088</td>\n      <td>0.170</td>\n      <td>50.0</td>\n      <td>85.0</td>\n      <td>3 oz</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 53 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "left_df.tail()"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "      NDB_No                   Shrt_Desc  Water_(g)  Energ_Kcal  Protein_(g)  \\\n8785   83110             MACKEREL,SALTED      43.00         305        18.50   \n8786   90240  SCALLOP,(BAY&SEA),CKD,STMD      70.25         111        20.54   \n8787   90480                  SYRUP,CANE      26.00         269         0.00   \n8788   90560                   SNAIL,RAW      79.20          90        16.10   \n8789   93600            TURTLE,GREEN,RAW      78.50          89        19.80   \n\n      Lipid_Tot_(g)  Ash_(g)  Carbohydrt_(g)  Fiber_TD_(g)  Sugar_Tot_(g)  \\\n8785          25.10    13.40            0.00           0.0            0.0   \n8786           0.84     2.97            5.41           0.0            0.0   \n8787           0.00     0.86           73.14           0.0           73.2   \n8788           1.40     1.30            2.00           0.0            0.0   \n8789           0.50     1.20            0.00           0.0            0.0   \n\n      ...  Vit_K_(ï¿½g)  FA_Sat_(g)  FA_Mono_(g)  FA_Poly_(g)  Cholestrl_(mg)  \\\n8785  ...           NaN         NaN          NaN          NaN             NaN   \n8786  ...           NaN         NaN          NaN          NaN             NaN   \n8787  ...           NaN         NaN          NaN          NaN             NaN   \n8788  ...           NaN         NaN          NaN          NaN             NaN   \n8789  ...           NaN         NaN          NaN          NaN             NaN   \n\n      GmWt_1  GmWt_Desc1  GmWt_2  GmWt_Desc2  Refuse_Pct  \n8785     NaN         NaN     NaN         NaN         NaN  \n8786     NaN         NaN     NaN         NaN         NaN  \n8787     NaN         NaN     NaN         NaN         NaN  \n8788     NaN         NaN     NaN         NaN         NaN  \n8789     NaN         NaN     NaN         NaN         NaN  \n\n[5 rows x 53 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>NDB_No</th>\n      <th>Shrt_Desc</th>\n      <th>Water_(g)</th>\n      <th>Energ_Kcal</th>\n      <th>Protein_(g)</th>\n      <th>Lipid_Tot_(g)</th>\n      <th>Ash_(g)</th>\n      <th>Carbohydrt_(g)</th>\n      <th>Fiber_TD_(g)</th>\n      <th>Sugar_Tot_(g)</th>\n      <th>...</th>\n      <th>Vit_K_(ï¿½g)</th>\n      <th>FA_Sat_(g)</th>\n      <th>FA_Mono_(g)</th>\n      <th>FA_Poly_(g)</th>\n      <th>Cholestrl_(mg)</th>\n      <th>GmWt_1</th>\n      <th>GmWt_Desc1</th>\n      <th>GmWt_2</th>\n      <th>GmWt_Desc2</th>\n      <th>Refuse_Pct</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8785</th>\n      <td>83110</td>\n      <td>MACKEREL,SALTED</td>\n      <td>43.00</td>\n      <td>305</td>\n      <td>18.50</td>\n      <td>25.10</td>\n      <td>13.40</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>8786</th>\n      <td>90240</td>\n      <td>SCALLOP,(BAY&amp;SEA),CKD,STMD</td>\n      <td>70.25</td>\n      <td>111</td>\n      <td>20.54</td>\n      <td>0.84</td>\n      <td>2.97</td>\n      <td>5.41</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>8787</th>\n      <td>90480</td>\n      <td>SYRUP,CANE</td>\n      <td>26.00</td>\n      <td>269</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.86</td>\n      <td>73.14</td>\n      <td>0.0</td>\n      <td>73.2</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>8788</th>\n      <td>90560</td>\n      <td>SNAIL,RAW</td>\n      <td>79.20</td>\n      <td>90</td>\n      <td>16.10</td>\n      <td>1.40</td>\n      <td>1.30</td>\n      <td>2.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>8789</th>\n      <td>93600</td>\n      <td>TURTLE,GREEN,RAW</td>\n      <td>78.50</td>\n      <td>89</td>\n      <td>19.80</td>\n      <td>0.50</td>\n      <td>1.20</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 53 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "There are differences here in the last five rows. Notice that the right-most columns of `left_df` contain have Not a Number (`NaN`) values. This is because the left `DataFrame` was larger than the right `DataFrame`. If you recall, we only took the first 2,000 rows from `df2`."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "> **Exercise**\n",
        "\n",
        "> A right join is simply the mirror image of a left join in which those entries from the left `DataFrame` that are common with the right `DataFrame` are merged with the right `DataFrame`.\n",
        ">\n",
        ">Perform a right join of `df1` and `df2` in the code cell below. But before you do that, ask yourself what shape you expect the resulting `DataFrame` to have? Do you expect it to have any `NaN` values?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "# Hint: the parameter for the right join is how='right'\n",
        ""
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "Another intuitive and widely used type of join is the inner join. This join simply merges entries that are common to both `DataFrame`s, resulting in a `DataFrame` that has no `NaN` values."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "inner_df = pd.merge(df1, df2, how='inner', on='NDB_No')"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "> **Question**\n",
        "\n",
        "> Before we examine the shape of the resulting `DataFrame`, what do you predict it will be? Why?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "inner_df.shape"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "(2000, 53)"
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "> **Question**\n",
        "\n",
        "> Why are there only 2,000 rows after performing an inner join between `df1` and `df2`?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "Did `inner_df` behave as you expected it would? Let's briefly examine it by using the `head()` and `tail()` methods."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "inner_df.head()"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "   NDB_No               Shrt_Desc  Water_(g)  Energ_Kcal  Protein_(g)  \\\n0    1001        BUTTER,WITH SALT      15.87         717         0.85   \n1    1002  BUTTER,WHIPPED,W/ SALT      16.72         718         0.49   \n2    1003    BUTTER OIL,ANHYDROUS       0.24         876         0.28   \n3    1004             CHEESE,BLUE      42.41         353        21.40   \n4    1005            CHEESE,BRICK      41.11         371        23.24   \n\n   Lipid_Tot_(g)  Ash_(g)  Carbohydrt_(g)  Fiber_TD_(g)  Sugar_Tot_(g)  ...  \\\n0          81.11     2.11            0.06           0.0           0.06  ...   \n1          78.30     1.62            2.87           0.0           0.06  ...   \n2          99.48     0.00            0.00           0.0           0.00  ...   \n3          28.74     5.11            2.34           0.0           0.50  ...   \n4          29.68     3.18            2.79           0.0           0.51  ...   \n\n   Vit_K_(ï¿½g)  FA_Sat_(g)  FA_Mono_(g)  FA_Poly_(g)  Cholestrl_(mg)  GmWt_1  \\\n0           7.0      51.368       21.021        3.043           215.0    5.00   \n1           4.6      45.390       19.874        3.331           225.0    3.80   \n2           8.6      61.924       28.732        3.694           256.0   12.80   \n3           2.4      18.669        7.778        0.800            75.0   28.35   \n4           2.5      18.764        8.598        0.784            94.0  132.00   \n\n                   GmWt_Desc1  GmWt_2       GmWt_Desc2  Refuse_Pct  \n0  1 pat,  (1\" sq, 1/3\" high)    14.2           1 tbsp         0.0  \n1  1 pat,  (1\" sq, 1/3\" high)     9.4           1 tbsp         0.0  \n2                      1 tbsp   205.0            1 cup         0.0  \n3                        1 oz    17.0     1 cubic inch         0.0  \n4                1 cup, diced   113.0  1 cup, shredded         0.0  \n\n[5 rows x 53 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>NDB_No</th>\n      <th>Shrt_Desc</th>\n      <th>Water_(g)</th>\n      <th>Energ_Kcal</th>\n      <th>Protein_(g)</th>\n      <th>Lipid_Tot_(g)</th>\n      <th>Ash_(g)</th>\n      <th>Carbohydrt_(g)</th>\n      <th>Fiber_TD_(g)</th>\n      <th>Sugar_Tot_(g)</th>\n      <th>...</th>\n      <th>Vit_K_(ï¿½g)</th>\n      <th>FA_Sat_(g)</th>\n      <th>FA_Mono_(g)</th>\n      <th>FA_Poly_(g)</th>\n      <th>Cholestrl_(mg)</th>\n      <th>GmWt_1</th>\n      <th>GmWt_Desc1</th>\n      <th>GmWt_2</th>\n      <th>GmWt_Desc2</th>\n      <th>Refuse_Pct</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1001</td>\n      <td>BUTTER,WITH SALT</td>\n      <td>15.87</td>\n      <td>717</td>\n      <td>0.85</td>\n      <td>81.11</td>\n      <td>2.11</td>\n      <td>0.06</td>\n      <td>0.0</td>\n      <td>0.06</td>\n      <td>...</td>\n      <td>7.0</td>\n      <td>51.368</td>\n      <td>21.021</td>\n      <td>3.043</td>\n      <td>215.0</td>\n      <td>5.00</td>\n      <td>1 pat,  (1\" sq, 1/3\" high)</td>\n      <td>14.2</td>\n      <td>1 tbsp</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1002</td>\n      <td>BUTTER,WHIPPED,W/ SALT</td>\n      <td>16.72</td>\n      <td>718</td>\n      <td>0.49</td>\n      <td>78.30</td>\n      <td>1.62</td>\n      <td>2.87</td>\n      <td>0.0</td>\n      <td>0.06</td>\n      <td>...</td>\n      <td>4.6</td>\n      <td>45.390</td>\n      <td>19.874</td>\n      <td>3.331</td>\n      <td>225.0</td>\n      <td>3.80</td>\n      <td>1 pat,  (1\" sq, 1/3\" high)</td>\n      <td>9.4</td>\n      <td>1 tbsp</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1003</td>\n      <td>BUTTER OIL,ANHYDROUS</td>\n      <td>0.24</td>\n      <td>876</td>\n      <td>0.28</td>\n      <td>99.48</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>8.6</td>\n      <td>61.924</td>\n      <td>28.732</td>\n      <td>3.694</td>\n      <td>256.0</td>\n      <td>12.80</td>\n      <td>1 tbsp</td>\n      <td>205.0</td>\n      <td>1 cup</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1004</td>\n      <td>CHEESE,BLUE</td>\n      <td>42.41</td>\n      <td>353</td>\n      <td>21.40</td>\n      <td>28.74</td>\n      <td>5.11</td>\n      <td>2.34</td>\n      <td>0.0</td>\n      <td>0.50</td>\n      <td>...</td>\n      <td>2.4</td>\n      <td>18.669</td>\n      <td>7.778</td>\n      <td>0.800</td>\n      <td>75.0</td>\n      <td>28.35</td>\n      <td>1 oz</td>\n      <td>17.0</td>\n      <td>1 cubic inch</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1005</td>\n      <td>CHEESE,BRICK</td>\n      <td>41.11</td>\n      <td>371</td>\n      <td>23.24</td>\n      <td>29.68</td>\n      <td>3.18</td>\n      <td>2.79</td>\n      <td>0.0</td>\n      <td>0.51</td>\n      <td>...</td>\n      <td>2.5</td>\n      <td>18.764</td>\n      <td>8.598</td>\n      <td>0.784</td>\n      <td>94.0</td>\n      <td>132.00</td>\n      <td>1 cup, diced</td>\n      <td>113.0</td>\n      <td>1 cup, shredded</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 53 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "inner_df.tail()"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "      NDB_No                                          Shrt_Desc  Water_(g)  \\\n1995    8538  CEREALS RTE,KASHI,HEART TO HEART,OAT FLAKES & ...        3.0   \n1996    8539     CEREALS RTE,KASHI ORGANIC PROMISE,CINN HARVEST        5.0   \n1997    8542  CEREALS RTE,KELLOGG'S,FRSTD MINI-WHEATS BITE S...        5.1   \n1998    8543         CEREALS RTE,KELLOGG'S,SPL K VANILLA ALMOND        3.0   \n1999    8544  CEREALS RTE,POST GREAT GRAINS CRANBERRY ALMOND...        6.2   \n\n      Energ_Kcal  Protein_(g)  Lipid_Tot_(g)  Ash_(g)  Carbohydrt_(g)  \\\n1995         376        10.39           3.79      2.5            80.3   \n1996         336        11.00           1.40      3.6            79.0   \n1997         352         8.70           1.60      0.5            84.6   \n1998         366         7.80           4.00      2.2            83.0   \n1999         384         8.90           5.90      2.4            76.6   \n\n      Fiber_TD_(g)  Sugar_Tot_(g)  ...  Vit_K_(ï¿½g)  FA_Sat_(g)  FA_Mono_(g)  \\\n1995           7.4           22.7  ...           1.9         0.8          1.1   \n1996          10.7           16.5  ...           NaN         0.2          0.2   \n1997          10.2           22.7  ...           NaN         0.4          0.2   \n1998           9.6           29.2  ...           0.7         0.4          2.0   \n1999          11.1           25.5  ...           2.0         0.8          3.0   \n\n      FA_Poly_(g)  Cholestrl_(mg)  GmWt_1                      GmWt_Desc1  \\\n1995          1.2             0.0    55.0        1 cup,  (1 NLEA serving)   \n1996          1.0             0.0    55.0  28 biscuits,  (1 NLEA serving)   \n1997          0.8             0.0    55.0  25 biscuits,  (1 NLEA serving)   \n1998          1.1             0.0    30.0      .75 cup,  (1 NLEA serving)   \n1999          1.7             0.0    48.0      .75 cup,  (1 NLEA serving)   \n\n      GmWt_2  GmWt_Desc2  Refuse_Pct  \n1995     NaN         NaN         0.0  \n1996     NaN         NaN         0.0  \n1997     NaN         NaN         0.0  \n1998     NaN         NaN         0.0  \n1999     NaN         NaN         0.0  \n\n[5 rows x 53 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>NDB_No</th>\n      <th>Shrt_Desc</th>\n      <th>Water_(g)</th>\n      <th>Energ_Kcal</th>\n      <th>Protein_(g)</th>\n      <th>Lipid_Tot_(g)</th>\n      <th>Ash_(g)</th>\n      <th>Carbohydrt_(g)</th>\n      <th>Fiber_TD_(g)</th>\n      <th>Sugar_Tot_(g)</th>\n      <th>...</th>\n      <th>Vit_K_(ï¿½g)</th>\n      <th>FA_Sat_(g)</th>\n      <th>FA_Mono_(g)</th>\n      <th>FA_Poly_(g)</th>\n      <th>Cholestrl_(mg)</th>\n      <th>GmWt_1</th>\n      <th>GmWt_Desc1</th>\n      <th>GmWt_2</th>\n      <th>GmWt_Desc2</th>\n      <th>Refuse_Pct</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1995</th>\n      <td>8538</td>\n      <td>CEREALS RTE,KASHI,HEART TO HEART,OAT FLAKES &amp; ...</td>\n      <td>3.0</td>\n      <td>376</td>\n      <td>10.39</td>\n      <td>3.79</td>\n      <td>2.5</td>\n      <td>80.3</td>\n      <td>7.4</td>\n      <td>22.7</td>\n      <td>...</td>\n      <td>1.9</td>\n      <td>0.8</td>\n      <td>1.1</td>\n      <td>1.2</td>\n      <td>0.0</td>\n      <td>55.0</td>\n      <td>1 cup,  (1 NLEA serving)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1996</th>\n      <td>8539</td>\n      <td>CEREALS RTE,KASHI ORGANIC PROMISE,CINN HARVEST</td>\n      <td>5.0</td>\n      <td>336</td>\n      <td>11.00</td>\n      <td>1.40</td>\n      <td>3.6</td>\n      <td>79.0</td>\n      <td>10.7</td>\n      <td>16.5</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>0.2</td>\n      <td>0.2</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>55.0</td>\n      <td>28 biscuits,  (1 NLEA serving)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1997</th>\n      <td>8542</td>\n      <td>CEREALS RTE,KELLOGG'S,FRSTD MINI-WHEATS BITE S...</td>\n      <td>5.1</td>\n      <td>352</td>\n      <td>8.70</td>\n      <td>1.60</td>\n      <td>0.5</td>\n      <td>84.6</td>\n      <td>10.2</td>\n      <td>22.7</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>0.4</td>\n      <td>0.2</td>\n      <td>0.8</td>\n      <td>0.0</td>\n      <td>55.0</td>\n      <td>25 biscuits,  (1 NLEA serving)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1998</th>\n      <td>8543</td>\n      <td>CEREALS RTE,KELLOGG'S,SPL K VANILLA ALMOND</td>\n      <td>3.0</td>\n      <td>366</td>\n      <td>7.80</td>\n      <td>4.00</td>\n      <td>2.2</td>\n      <td>83.0</td>\n      <td>9.6</td>\n      <td>29.2</td>\n      <td>...</td>\n      <td>0.7</td>\n      <td>0.4</td>\n      <td>2.0</td>\n      <td>1.1</td>\n      <td>0.0</td>\n      <td>30.0</td>\n      <td>.75 cup,  (1 NLEA serving)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1999</th>\n      <td>8544</td>\n      <td>CEREALS RTE,POST GREAT GRAINS CRANBERRY ALMOND...</td>\n      <td>6.2</td>\n      <td>384</td>\n      <td>8.90</td>\n      <td>5.90</td>\n      <td>2.4</td>\n      <td>76.6</td>\n      <td>11.1</td>\n      <td>25.5</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>0.8</td>\n      <td>3.0</td>\n      <td>1.7</td>\n      <td>0.0</td>\n      <td>48.0</td>\n      <td>.75 cup,  (1 NLEA serving)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 53 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "The resulting `DataFrame` is essentially the first 2000 rows of the original `df` `DataFrame`."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "> **Exercise**\n",
        "\n",
        "> An outer join is the union of two `DataFrame`s; anything that is in either `DataFrame` with be in the resultant one. Perform an outer join of `df1` and `df2`. What shape do you expect the resulting `DataFrame` to have? How does it differ from the right join of `df1` and `df2`? What differences would there have to be in the shape or content of either `DataFrame` for the outer join of the two to be different from their right join?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "## Preparing for coming sections\n",
        "\n",
        "We will be using the USDA NNDB dataset in Sections 1.2 and 1.3. However, particularly in Section 1.2, we want to include food group information to go with the food entries to aid with interpreting the result of our data analysis in that section. You will add food group information to this USDA dataset in preparation for these coming sections.\n",
        "\n",
        "First, let's reload our original NNDB dataset so that we have a clean copy."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('Data/USDA-nndb.csv', encoding='latin_1')"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "Now let's load in the columns that we want from the older NNDB dataset that includes food groups."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "fg_df = pd.read_csv('Data/USDA-nndb-combined.csv', usecols=['NDB_No', 'FoodGroup'])\n",
        "fg_df.head()"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "   NDB_No               FoodGroup\n0    1001  Dairy and Egg Products\n1    1002  Dairy and Egg Products\n2    1003  Dairy and Egg Products\n3    1004  Dairy and Egg Products\n4    1005  Dairy and Egg Products",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>NDB_No</th>\n      <th>FoodGroup</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1001</td>\n      <td>Dairy and Egg Products</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1002</td>\n      <td>Dairy and Egg Products</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1003</td>\n      <td>Dairy and Egg Products</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1004</td>\n      <td>Dairy and Egg Products</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1005</td>\n      <td>Dairy and Egg Products</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "Note that `fg_df` does not have the same number of rows as `df`:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "fg_df.shape"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "(8989, 2)"
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "> **Exercise**\n",
        ">\n",
        "> We need to combine `df` and `fg_df` using the pandas `merge()` function. As you prepare to do so, keep the following considerations front of mind:\n",
        "> 1. Which type of join should you use to capture all of the information in both datasets? (**Hint:** Look at the `head` and `tail` of the resulting `DataFrame` for clues.)\n",
        "> 2. In order to put the `FoodGroup` column immediately after the `NDB_No` column, in what order should you enter the two `DataFrame`s into the `merge()` function? (You might need to experiment a couple of times to get the desired order.)\n",
        ">\n",
        "> Perform the command to join the `df` and `fg_df` in the code cell below."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "combined_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "combined_df.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "Now save the merged `DataFrame` using the `to_csv()` method."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "combined_df.to_csv('Data/USDA-nndb-merged.csv', \n",
        "                   sep=',', \n",
        "                   encoding='latin_1', \n",
        "                   index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "> **Takeaway:** Because the most interesting insights come from joining different datasets, the pandas `merge()` function is at the heart of most data science projects."
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "file_extension": ".py",
      "version": "3.7.6-final",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}